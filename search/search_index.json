{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Uberon Ontology Documentation","text":""},{"location":"#quick-links","title":"Quick links:","text":"<ul> <li>Uberon on Github</li> <li>Issue Tracker</li> <li>Browse Uberon on OLS</li> <li>About Uberon</li> <li>The Uberon Team</li> </ul>"},{"location":"about/","title":"About UBERON","text":"<p>Uberon is an anatomical ontology that represents body parts, organs and tissues in a variety of animal species, with a focus on vertebrates. It has been constructed to integrate seamlessly with other ontologies, such as the OBO Cell Ontology workflows, the Gene Ontology, Trait and Phenotype ontologies, as well as other anatomical ontologies.</p> <p>The ontology includes comprehensive relationships to taxon-specific anatomical ontologies, allowing integration of functional, phenotype and expression data. The figure below shows taxon-centric anatomy ontologies along the bottom axis; domain specific ontologies on the right hand side; orthogonal ontologies on the left axis.</p> <p></p> <p>Currently Uberon consists of over 13000 classes representing structures that are shared across a variety of metazoans. As one of the main uses of Uberon is translational science, we have extensive coverage of structures shared between humans and other species. However, thanks to the involvement of many collaborators, we have deep coverage of broad areas of anatomy across diverse taxa.</p> <p>We also make available an ontology called composite-metazoan which brings in subsets of federated ontologies, with a total of over 40000 classes.</p>"},{"location":"acknowledgements/","title":"Contributing Organizations","text":"<p>See the list of adopters, many of whom are also contributing content to the ontology.</p>"},{"location":"acknowledgements/#ontologies","title":"Ontologies","text":"<p>Uberon has been developed in conjunction with a number of other bio-ontologies, in particular - ZFA (Zebrafish) - XAO (Xenopus) - TAO (Teleost, now included in Uberon) - AAO (Amphibia, now included in Uberon) - VSAO (Vertebrate Skeleton, now included in Uberon) - MA (Adult Mouse) - EMAPA (Developmental Mouse) - EHDAA2 (Developmental Human) - FMA (Adult Human) - FBbt (Drosophila) - WBbt (C elegans) - MP (Mouse Phenotype) - HP (Human Phenotype) - GO (Gene Ontology) - FEED (Mammalian Feeding Muscles) - CL (Cell Type)</p>"},{"location":"acknowledgements/#technology","title":"Technology","text":"<p>Uberon shares a similar technology stack to many other bio-ontologies. Key contributors to this stack include Heiko Dietze, Seth Carbon, James Balhoff, Frederic Bastian, Alan Ruttenberg, David Osumi-Sutherland, James A. Overton.</p>"},{"location":"acknowledgements/#the-elk-reasoner","title":"The Elk Reasoner","text":"<p>We use a variety of reasoners, but like most bio-ontologies, the game changer for us has been the fantastic Elk reasoner.</p> <p>ELK has been created in the Knowledge Representation and Reasoning group at the Department of Computer Science of the University of Oxford. Development has been supported by the EPSRC under the research project ConDOR: Consequence-Driven Ontology Reasoning (grant number EP/G02085X/1).</p> <p>We are also grateful to the developers of HermiT and FACT++, which are also used during development.</p>"},{"location":"acknowledgements/#owl-api","title":"OWL API","text":"<p>The OWL API is a Java API and reference implmentation for creating, manipulating and serialising OWL Ontologies. The current Uberon development and build infrastructure relies heavily on the OWLAPI. Many thanks to the OWLAPI developers, especially Ignazio Palmisano and Matt Horridge.</p> <p>In particular, we make use of an in-house library developed for the GO called owltools, and the ROBOT ontology manipulation tool developed for the OBO Foundry. Both are built on top of the OWL API.</p>"},{"location":"acknowledgements/#swi-prolog","title":"SWI-Prolog","text":"<p>Early versions of the ontology were created using a combination of text mining and rule-based reasoning approaches. This would not have been possible without SWI-Prolog.</p>"},{"location":"acknowledgements/#hosting","title":"Hosting","text":"<p>We use github for hosting.</p>"},{"location":"adopters/","title":"Uberon Adopters","text":""},{"location":"adopters/#phenoscape","title":"Phenoscape","text":"<p>The Phenoscape projects collects and analyzes phenotypic character descriptions from a range of vertebrate species, using Uberon and PATO to describe evolutionary character states.</p> <p>The Phenoscape project is both a major driver of and contributor to Uberon, contributing thousands of terms. The teleost (bony fishes) component of Uberon was derived from the Teleost Anatomy Ontology, developed by the Phenoscape group. Most of the high level design of the skeletal system comes from the Vertebrate Skeletal Anatomy Ontology (VSAO), also created by the Phenoscape group. Phenoscape curators continue to extend the ontology, covering a wide variety of tetrapod structures, with an emphasis on the appendicular system.</p> <p>See the Phenoscape website for more details</p>"},{"location":"adopters/#bgee","title":"Bgee","text":"<p>Bgee is a database to retrieve and compare gene expression patterns between animal species. Bgee in using Uberon to annotate the site of expression, and Bgee curators one the major contributors to the ontology.</p> <p>BGee</p>"},{"location":"adopters/#gene-ontology","title":"Gene Ontology","text":"<p>The Gene Ontology uses Uberon to classify developmental processes, and to provide additional contextual information on annotations, such as the location of a biological process.</p> <p>See the GO website</p>"},{"location":"adopters/#monarch-initiative","title":"Monarch Initiative","text":"<p>Model systems are the cornerstone of biomedical research to investigate biological processes, test gene-based disease hypotheses, and develop and test disease treatments. The vast knowledge that we have about model systems can be better utilized if semantically aggregated and made queryable based on any number of facets, such as phenotypic similarity, network analysis, gene expression and function, and genomics. The Monarch Initiative aims to provide easy-to-use tools to navigate this data landscape, services for other resources, and educational outreach regarding the production of structured data for biomedical discovery.</p> <p>The user of Uberon to bridge between different species is key to the phenotype mapping component of this project.</p> <p>See the Monarch Initiative website for more details</p>"},{"location":"adopters/#ebi","title":"EBI","text":"<p>The EBI Samples Phenotypes and Ontology Team is using Uberon for describing biological samples and phenotypes. Recently, Uberon was integrated with the EFO (Experimental Factory Ontology), developed by the SPOT group.</p>"},{"location":"adopters/#global-alliance-for-genomes-and-health","title":"Global Alliance for Genomes and Health","text":"<p>The Global Alliance for Genomes and Health is an international coalition, dedicated to improving human health by maximizing the potential of genomic medicine through effective and responsible data sharing.</p> <p>The Global Alliance Data Working Group has proposed Uberon and the CL as a standard for the description of biological samples. See the metadata schema:</p>"},{"location":"adopters/#eagle-i","title":"eagle i","text":"<p>The eagle i project uses Uberon anatomical structures to collect information about cell lines and biospecimens. Since eagle-i is often concerned with non-model organism resources, Uberon + Taxonomy is the ideal mechanism to assert the source anatomical structure for these resources.</p>"},{"location":"adopters/#fantom5","title":"FANTOM5","text":"<p>FANTOM is an international research consortium established by Dr. Hayashizaki and his colleagues in 2000 to assign functional annotations to the full-length cDNAs that were collected during the Mouse Encyclopedia Project at RIKEN. FANTOM has since developed and expanded over time to encompass the fields of transcriptome analysis. The object of the project is moving steadily up the layers in the system of life, progressing thus from an understanding of the \u2018elements\u2019 - the transcripts - to an understanding of the \u2018system\u2019 - the transcriptional regulatory network, in other words the \u2018system\u2019 of an individual life form.</p> <p>FANTOM5 is using Uberon and CL to annotate samples allowing for transcriptome analyses with cell-type and tissue-level specificity.</p> <p>See FANTOM website</p>"},{"location":"adopters/#encode","title":"ENCODE","text":"<p>The National Human Genome Research Institute (NHGRI) launched a public research consortium named ENCODE, the Encyclopedia Of DNA Elements, in September 2003, to carry out a project to identify all functional elements in the human genome sequence.</p> <p>The ENCODE Data Collection Center (DCC) uses a core set of ontologies: - UBERON - CL - EFO - OBI - ChEBI - SO - GO - See ENCODE DCC Ontologies</p> <p>Malladi, V. S., Erickson, D. T., Podduturi, N. R., Rowe, L. D., Chan, E. T., Davidson, J. M., \u2026 Hong, E. L. (2015). Ontology application and use at the ENCODE DCC. Database : The Journal of Biological Databases and Curation, 2015, bav010\u2013. doi:10.1093/database/bav010</p> <p>Sloan, C. A., Chan, E. T., Davidson, J. M., Malladi, V. S., Strattan, J. S., Hitz, B. C., \u2026 Cherry, J. M. (2015). ENCODE data at the ENCODE portal. Nucleic Acids Research, gkv1160\u2013. doi:10.1093/nar/gkv1160</p>"},{"location":"adopters/#nextprot","title":"neXtProt","text":"<p>neXtProt is an on-line knowledge platform on human proteins. It strives to be a comprehensive resource that provides a variety of types of information on human proteins, such as their function, subcellular location, expression, interactions and role in diseases.</p> <p>neXtProt is using Uberon as the main vaculary for describing site of protein localization in animals.</p>"},{"location":"adopters/#feed","title":"FEED","text":"<p>The NSF FEED (Feeding Experiments End-user Group) working group is developing a database of mammalian feeding muscle data. The FEED developers are responsible for the craniofacial muscle aspects of Uberon.</p>"},{"location":"adopters/#scicrunch","title":"SciCrunch","text":"<p>Uberon is the anatomical ontology used as part of the SciCrunch integrated search system and dkNET projects.</p>"},{"location":"adopters/#cellpedia","title":"CELLPEDIA","text":"<p>See Hatano et al in Database</p>"},{"location":"adopters/#international-human-epigenomics-consortium","title":"International Human Epigenomics Consortium","text":"<p>The International Human Epigenome Consortium (IHEC) is a global consortium with the primary goal of providing free access to high-resolution reference human epigenome maps for normal and disease cell types to the research community. IHEC is working to define standards for epigenomic mapping and metadata. Uberon and CL are the IHEC standard ontologies for tissue and cell line names.</p> <p>For more details, see the IHEC Standards page.</p>"},{"location":"adopters/#nih-lincs","title":"NIH LINCS","text":"<p>The NIH Library of Integrated Network-based Cellular Signatures (LINCS) project aims to create a network-based understanding of biology by cataloging changes in gene expression and other cellular processes that occur when cells are exposed to a variety of perturbing agents, and by using computational tools to integrate this diverse information into a comprehensive view of normal and disease states that can be applied for the development of new biomarkers and therapeutics.</p> <p>This project recommends the usage of Uberon and the OBO Cell Ontology for describing organs, tissues and cells for annotating reagents and assays.</p> <p>See Vempati et al</p>"},{"location":"adopters/#the-alexandria-archive-institute","title":"The Alexandria Archive Institute","text":"<p>In September, 2012, the AAI launched Exploring Biogeography of Early Domestic Animals using Linked Open Data, a one-year project using Linked Open Data to enhance archaeological data sets. Skeletal element data are also linked using Uberon.</p> <p>See:</p> <p>linked data Mixing Models for Communicating Research Data in Archaeology, Kansa et al, International Journal for Digital Curation,Vol 9, No. 1 (2014)</p>"},{"location":"bridges/","title":"Uberon bridge files","text":"<p>Uberon provides bridge files for several foreign ontologies, especially species-specific anatomy ontologies (ssAOs). Each bridge file contains bridging axioms that establish a relationship between a Uberon term and a term from the foreign ontology.</p> <p>For example, the <code>uberon-bridge-to-zfa</code> bridge contains axioms such as this one:</p> <p>ZFA:0001262 EquivalentTo: UBERON:0005564 and (RO:0002162 some NCBITaxon:7954)</p> <p>which states that ZFA\u2019s gonad primordium (ZFA:0001262) is equivalent to a Uberon\u2019s gonad primordium (UBERON:0005564) that is in taxon some Danio (NCBITaxon:7954).</p> <p>Such a bridge may be used by anyone who wants to merge Uberon and ZFA to obtain an integrated ontology in which the Danio-specific terms in ZFA are properly linked to their taxon-neutral counterparts in Uberon. Internally, Uberon itself is using those bridges to produce the combined multispecies ontologies such as <code>composite-metazoan</code>.</p> <p>In addition to the bridging axioms proper, the bridges also contain an additional annotation for each bridged term: a \u201cOBO Foundry unique label\u201d (<code>IAO:0000589</code>). That label is automatically derived from the standard <code>rdfs:label</code> of the term, to which a suffix indicating the taxon is appended (for example in the case of <code>ZFA:0001262</code>, the unique label is \u201cgonad primordium (zebrafish)\u201d). This is to ensure that, upon merging Uberon with taxon-specific ontologies, all the terms in the merged ontology will have a distinct label.</p> <p>Note that the bridges between the Cell Ontology (CL) and the species-specific anatomy ontologies are also provided by Uberon, rather by CL directly. This is because the pipeline that produces those bridges (briefly described below) is entirely hosted in the Uberon repository.</p> <p>The latest bridge files can be found on GitHub.</p>"},{"location":"bridges/#sources-of-truth","title":"Sources of truth","text":"<p>Each bridge has one source of truth which may be:</p> <ul> <li>cross-references in Uberon or CL;</li> <li>cross-references in the foreign ontology;</li> <li>an externally provided mapping set;</li> <li>an externally provided custom bridge.</li> </ul>"},{"location":"bridges/#cross-references-in-uberon-or-cl","title":"Cross-references in Uberon or CL","text":"<p>Cross-references are currently the source of truth for most bridges. For such bridges, a Uberon or CL term will carry a <code>oboInOwl:hasDbXref</code> annotation (aka a \u201cOBO-style cross-reference\u201d) whose value is the short identifier of the foreign term that is, by virtue of this cross-reference, being mapped to the Uberon or CL term.</p> <p>For example, Uberon contains the following annotation assertion:</p> <p>AnnotationAssertion(oboInOwl:hasDbXref UBERON:0005564 \"ZFA:0001262\")</p> <p>by which Uberon\u2019s gonad primordium is mapped to the equivalent term in ZFA.</p> <p>The annotations are present directly in the <code>-edit</code> file and may be edited by curators as they wish, using e.g. Prot\u00e9g\u00e9.</p> <p>Note that for an annotation such as the one above to be used when producing the bridge files, the prefix used in the annotation (in this example <code>ZFA</code>) must be declared in an ontology-level annotation that will indicate the signification of the mapping. In the case of ZFA, the declaration is as follows:</p> <p>Annotation(oboInOwl:treat-xrefs-as-reverse-genus-differentia \"ZFA part_of NCBITaxon:7954\")</p> <p>and it indicates that any mapping between a Uberon term and a term from ZFA should result, when producing the bridge files, in a axiom that states that the ZFA term is equivalent to the intersection of the Uberon term and the existential restriction <code>part_of some Danio</code>.</p> <p>Curators should not normally have to worry about declaring the prefixes of foreign ontologies that Uberon provides bridges for, unless they want to create a completely new bridge (which presumably should not be needed often). But for reference, here are the other possible declaration annotations and the meaning they give to the mappings:</p> <ul> <li><code>oboInOwl:treat-xrefs-as-equivalent \"PFX\"</code>: indicates that terms in   the PFX namespace are equivalent to the Uberon or CL terms they are   mapped to;</li> <li><code>oboInOwl:treat-xrefs-as-is_a \"PFX\"</code>: indicates that terms in the   PFX namespace are parents of the Uberon or CL terms they are mapped   to;</li> <li><code>oboInOwl:treat-xrefs-as-has-subclass \"PFX\"</code>: indicates that terms in   the PFX namespaces are subclasses of the Uberon or CL terms they are   mapped to.</li> </ul>"},{"location":"bridges/#cross-references-in-the-foreign-ontology","title":"Cross-references in the foreign ontology","text":"<p>Some foreign ontologies maintain their own mappings with Uberon and/or CL, using the same cross-reference-based system as used in Uberon and CL and described above. In such cases, when generating the bridges Uberon obtains the cross-references from the foreign ontologies and then derives the bridging axioms from them in the same way as is done for cross-references maintained internally in Uberon and CL.</p> <p>Uberon or CL editors wishing to amend the mappings with an ontology that maintain its own mappings should contact the editors of that ontology directly, as the mappings cannot be edited directly within Uberon or CL. Adding a cross-reference in Uberon or CL is possible but will have no effect on the bridges.</p>"},{"location":"bridges/#externally-provided-mapping-sets","title":"Externally provided mapping sets","text":"<p>Some foreign ontologies maintain their own mappings with Uberon and/or CL, and provide the mappings in the form of a SSSOM mapping set. For such ontologies, Uberon simply uses the mapping set as provided and derives the bridging axioms from it. In that case, Uberon or CL editors wishing to amend the mappings should contact the editors of the foreign ontology, as the mappings cannot be edited directly within Uberon/CL. Adding a cross-reference in Uberon or CL will have no effect.</p>"},{"location":"bridges/#externally-provided-custom-bridges","title":"Externally provided custom bridges","text":"<p>Some foreign sources provide \u201ccustom\u201d or \u201ccomplex\u201d bridge files that they generate on their side using whatever pipeline they need. Uberon simply uses those bridge files as they are. As for the case of externally provided mapping sets, Uberon or CL editors wishing to amend those bridges should contact the upstream source.</p>"},{"location":"bridges/#the-bridges","title":"The bridges","text":"<p>The following is a list of all the current bridges, along with their current source of truth.</p>"},{"location":"bridges/#bridges-with-uberon","title":"Bridges with Uberon","text":"Bridge name Foreign ontology Source of truth <code>uberon-bridge-to-aeo.owl</code> Anatomical entity ontology (AEO) AEO xrefs in Uberon <code>uberon-bridge-to-bfo.owl</code> Basic formal ontology (BFO) BFO xrefs in Uberon <code>uberon-bridge-to-caro.owl</code> Common anatomy reference ontology (CARO) CARO xrefs in Uberon <code>uberon-bridge-to-dhba.owl</code> Developing human brain atlas (DHBA) DHBA xrefs in Uberon <code>uberon-bridge-to-dmba.owl</code> Developing mouse brain atlas (DMBA) Externally provided custom bridge, maintained here <code>uberon-bridge-to-ehdaa2.owl</code> Human developmental anatomy (EHDAA2) EHDAA2 xrefs in Uberon <code>uberon-bridge-to-emapa.owl</code> Mouse developmental anatomy ontology (EMAPA) EMAPA xrefs in Uberon <code>uberon-bridge-to-fbbt.owl</code> Drosophila anatomy ontology (FBbt) FBbt-maintained mapping set <code>uberon-bridge-to-fbdv.owl</code> Drosophila development ontology (FBdv) FBdv xrefs in Uberon <code>uberon-bridge-to-fma.owl</code> Foundational model of anatomy ontology (FMA) FMA xrefs in Uberon <code>uberon-bridge-to-go.owl</code> Gene ontology (GO) GO xrefs in Uberon <code>uberon-bridge-to-hao.owl</code> Hymenoptera anatomy ontology (HAO) HAO xrefs in Uberon <code>uberon-bridge-to-hba.owl</code> Human brain atlas (HBA) HBA xrefs in Uberon <code>uberon-bridge-to-hsapdv.owl</code> Human developmental stages (HsapDv) SSLSO-maintained mapping set <code>uberon-bridge-to-kupo.owl</code> Kidney and urinary pathway ontology (KUPO) KUPO xrefs in Uberon <code>uberon-bridge-to-ma.owl</code> Mouse adult gross anatomy (MA) MA xrefs in Uberon <code>uberon-bridge-to-mba.owl</code> Mouse brain atlas (MBA) Externally provided custom bridge, maintained here <code>uberon-bridge-to-mmusdv.owl</code> Mouse developmental stages (MmusDv) SSLSO-maintained mapping set <code>uberon-bridge-to-ncit.owl</code> NCI thesaurus OBO edition (NCIT) NCIT xrefs in Uberon <code>uberon-bridge-to-oges.owl</code> ? OGES xrefs in Uberon <code>uberon-bridge-to-pba.owl</code> Primate brain atlas (PBA) PBA xrefs in Uberon <code>uberon-bridge-to-sctid.owl</code> SNOMED CT (SCTID) SCTID xrefs in Uberon <code>uberon-bridge-to-spd.owl</code> Spider ontology (SPD) SPD xrefs in Uberon <code>uberon-bridge-to-sslso.owl</code> Species-specific life stages ontology (SSLSO) SSLSO-maintained mapping set <code>uberon-bridge-to-tads.owl</code> Tick anatomy ontology (TADS) TADS xrefs in Uberon <code>uberon-bridge-to-tgma.owl</code> Mosquito gross anatomy ontology (TGMA) TGMA xrefs in Uberon <code>uberon-bridge-to-wbbt.owl</code> C. elegans gross anatomy ontology (WBbt) WBbt xrefs in Uberon <code>uberon-bridge-to-wbls.owl</code> C. elegans development ontology (WBls) WBls xrefs in Uberon <code>uberon-bridge-to-xao.owl</code> Xenopus anatomy ontology (XAO) XAO xrefs in Uberon <code>uberon-bridge-to-zfa.owl</code> Zebrafish anatomy ontology (ZFA) ZFA xrefs in Uberon <code>uberon-bridge-to-zfs.owl</code> Zebrafish developmental stages (ZFS) ZFS xrefs in Uberon"},{"location":"bridges/#bridges-with-cl","title":"Bridges with CL","text":"Bridge name Foreign ontology Source of truth <code>cl-bridge-to-aeo.owl</code> Anatomical entity ontology (AEO) AEO xrefs in CL <code>cl-bridge-to-caro.owl</code> Common anatomy reference ontology (CARO) CARO xrefs in CL <code>cl-bridge-to-ehdaa2.owl</code> Human developmental anatomy (EHDAA2) EHDAA2 xrefs in CL <code>cl-bridge-to-emapa.owl</code> Mouse developmental anatomy ontology (EMAPA) EMAPA xrefs in EMAPA <code>cl-bridge-to-fbbt.owl</code> Drosophila anatomy ontology (FBbt) FBbt-maintained mapping set <code>cl-bridge-to-fma.owl</code> Foundational model of anatomy ontology (FMA) FMA xrefs in CL <code>cl-bridge-to-go.owl</code> Gene ontology (GO) GO xrefs im CL <code>cl-bridge-to-kupo.owl</code> Kidney and urinary pathway ontology (KUPO) KUPO xrefs in CL <code>cl-bridge-to-ma.owl</code> Mouse adult gross anatomy (MA) MA xrefs in CL <code>cl-bridge-to-ncit.owl</code> NCI thesaurus OBO edition (NCIT) NCIT xrefs in CL <code>cl-bridge-to-sctid.owl</code> SNOMED CT (SCTID) SCTID xrefs in CL <code>cl-bridge-to-wbbt.owl</code> C. elegans gross anatomy ontology (WBbt) WBbt xrefs in CL <code>cl-bridge-to-xao.owl</code> Xenopus anatomy ontology (XAO) XAO xrefs in CL <code>cl-bridge-to-zfa.owl</code> Zebrafish anatomy ontology (ZFA) CL xrefs in ZFA, maintained here"},{"location":"bridges/#producing-the-bridges","title":"Producing the bridges","text":"<p>This section is a (very) brief overview of the pipeline that generates the bridge files.</p> <p>The pipeline may be triggered by invoking the Make target <code>refresh-bridges</code> (whilst in the in <code>src/ontology</code> directory, where the Makefile is located). Here is what happens then:</p> <ol> <li>Production of a SSSOM mapping set from the Uberon cross-references.    Cross-references are extracted directly from the Uberon <code>-edit</code> file    and turned into a SSSOM mapping set. This takes care of all the    mappings with the foreign ontologies for which Uberon is the source    of truth.</li> <li>Production of a SSSOM mapping sets from ontologies that maintain    their own mappings as cross-references. The foreign ontologies are    downloaded and their cross-references are extracted in the same way    as the Uberon cross-references are. Note that currently there is no    such ontology.</li> <li>Fetching of externally maintained mapping sets. For ontologies that    maintain their own mappings and provide a SSSOM mapping set directly,    we fetch the mapping set as it is. This currently concerns FBbt and    CL (the CL set brings with it the mappings between CL and all the    species-specific ontologies).</li> <li>Merging of all the mapping sets. We merge the SSSOM mapping set that    was derived from the Uberon cross-references (step 1), the sets that    were derived from the cross-references of foreign ontologies    (step 2), and the sets that we obtained directly from foreign    ontologies (step 3).</li> <li>Production of the bridges. We apply a large SSSOM/T-OWL ruleset    (derived from <code>bridge/bridges.rules</code>, see below for more details about    that ruleset) to produce bridging axioms from the mappings in the    combined mapping set obtained at step 4.</li> <li>Dispatching into individual bridges. The axioms produced at step 5    are written to different bridges depending on the ontologies they are    bridging (e.g., an axiom that bridges a Uberon term and a ZFA term    will be written to the <code>uberon-bridge-to-zfa.owl</code> bridge file).</li> <li>Fetching the custom bridges. Independently of all the previous steps,    the \u201ccustom\u201d bridges are fetched from their upstream source.</li> </ol> <p>Note that steps 2, 3, and 7 only happen when the Make variable <code>IMP</code> is set to <code>true</code> (which is always the case when the pipeline is explicitly triggered with <code>make refresh-bridges</code>). When <code>IMP</code> is set to <code>false</code>, the bridge files are re-generated using only locally available resources previously committed to the repository.</p> <p>Uberon maintainers should run <code>make refresh-bridges</code> periodically to refresh external resources and commit refreshed versions to the repository, similarly to what is needed to refresh the imports.</p>"},{"location":"bridges/#the-bridging-sssomt-owl-ruleset","title":"The bridging SSSOM/T-OWL ruleset","text":"<p>The SSSOM/T-OWL ruleset mentioned in step 5 above is where most of the logic for the production of bridge files is described. For a general overview of the SSSOM/T-OWL language, please refer to the corresponding documentation in the SSSOM-Java project.</p> <p>Because the ruleset is highly repetitive, with many almost identical rules for every species we need to bridge to, it is partially automatically generated from a taxa list found in the <code>config/taxa.yaml</code> file.</p> <p>An entry in the taxa list should look like the following:</p> <pre><code>taxon_id: NCBITaxon:7227\nlabel: D melanogaster\nbridging:\n  - prefix: FBbt\n    namespace: http://purl.obolibrary.org/obo/FBbt_\n    label: D melanogaster\n    name: fbbt\n  - prefix: FBdv\n    namespace: http://purl.obolibrary.org/obo/FBdv_\n    label: D melanogaster\n    name: fbdv\n</code></pre> <ul> <li><code>taxon_id</code> is the NCBI taxonomic identifier for the species we are   bridging to.</li> <li><code>label</code> is the human-readable name of the taxon.</li> <li><code>bridging</code> is the list of bridges (there may be more than one, as in   example above) for that taxon.</li> </ul> <p>Each bridge is in turn described by:</p> <ul> <li>the <code>prefix</code> identifying the terms the bridge should include;</li> <li>the corresponding <code>namespace</code> the prefix expands to;</li> <li>the human-readable <code>label</code> of the taxon that should be appended to the   label of each bridged term to form the \u201cOBO Foundry Unique Label\u201d;</li> <li>the <code>name</code> of the bridge, which will be used to form the name of the   bridge file (<code>uberon-bridge-to-NAME.owl</code>).</li> </ul> <p>So, the example above states that <code>FBbt:*</code> terms (terms in the <code>http://purl.obolibrary.org/obo/FBbt_</code> namespace) mapped to Uberon terms should yield bridging axioms in a <code>uberon-bridge-to-fbbt.owl</code> bridge file, while <code>FBdv:*</code> terms (in the <code>http://purl.obolibrary.org/obo/FBdv_</code> namespace) mapped to Uberon terms should yield bridging axioms in a <code>uberon-bridge-to-fbdv.owl</code> file. In all cases, the bridged terms should be annotated with a \u201cOBO Foundry Unique Label\u201d annotation of the form \u201cUberon label (D melanogaster)\u201d.</p> <p>Note that:</p> <ul> <li>If a bridge does not have an explicit <code>namespace</code>, a default namespace   of <code>http://purl.obolibrary.org/obo/PREFIX_</code> is used.</li> <li>If a bridge does not have an explicit <code>label</code>, the top-level <code>label</code>   for the taxon is used.</li> <li>If a bridge does not have an explicit <code>name</code>, the default name is the   lowercase version of the prefix.</li> </ul> <p>Those default rules mean that the example above can be written more simply as:</p> <pre><code>taxon_id: NCBITaxon:7227\nlabel: D melanogaster\nbridging:\n  - prefix: FBbt\n  - prefix: FBdv\n</code></pre>"},{"location":"cite/","title":"How to cite UBERON","text":"<p>Uberon, an integrative multi-species anatomy ontology Mungall, C. J., Torniai, C., Gkoutos, G. V., Lewis, S. E., and Haendel, M. A. (2012) Genome Biology 13, R5. PMID:22293552</p> <p>Unification of multi-species vertebrate anatomy ontologies for comparative biology in Uberon Haendel, Melissa A; Balhoff, James P; Bastian, Frederic B; Blackburn, David C; Blake, Judith A; Bradford, Yvonne; Comte, Aurelie; Dahdul, Wasila M; Dececchi, Thomas A; Druzinsky, Robert E; Hayamizu, Terry F; Ibrahim, Nizar; Lewis, Suzanna E; Mabee, Paula M; Niknejad, Anne; Robinson-Rechavi, Marc; Sereno, Paul C; Mungall, Christopher J (2014) Journal of Biomedical Semantics, 5(1), 21. doi:10.1186/2041-1480-5-21</p>"},{"location":"cite/#papers-referencing-uberon","title":"Papers referencing UBERON","text":"<p>Google scholar link</p>"},{"location":"cite/#posters-and-presentations","title":"Posters and Presentations","text":"<ul> <li>Structuring Phenotype Data for Invertebrate Genomes - Chris Mungall, GIGA2 2015</li> <li>From baleen to cleft palate: an ontological exploration of evolution and disease - Melissa Haendel, Keynote, Bio-Ontologies 2014</li> <li>Semantics of and for the diversity of life:\u2028 Opportunities and perils of trying to reason on the frontier - Hilmar Lapp, Keynote, CSHALS 2014</li> <li>Uberon - Chris Mungall, EBI Industry Workshop, 2013</li> <li>Use of Uberon in the Bgee database - Frederic Bastian, Biocuration, 2013</li> <li>Using ontologies to enhance integration and analyses of ENCODE data - Venkat Malladi, Biocuration, 2013</li> <li>Uberon and (Zoo)archaeology - Eric Kansa, NSF Phenotype RCN 2012</li> <li>Hiding ontologies under the carpet - Frederic Bastian, OntoSIB, 2012</li> <li>Uberon - Melissa Haendel, Cell Ontology Workshop, 2010</li> </ul>"},{"location":"combined_multispecies/","title":"Combined Multispecies Ontologies","text":"<p>This document describes the multi-species products of Uberon and how they are built. It is an updated version of the documentation from the old Uberon Wiki, especially the following pages: Multi-species importer ontologies and Multi-species composite ontologies.</p>"},{"location":"combined_multispecies/#types-of-multi-species-ontologies","title":"Types of multi-species ontologies.","text":"<p>Uberon provides two distinct types of multi-species products: collected ontologies and composite ontologies.</p>"},{"location":"combined_multispecies/#collected-ontologies","title":"Collected ontologies","text":"<p>A collected ontology is obtained by merging Uberon itself, the Cell Ontology (CL), one or several taxon-specific anatomy ontologies, along with, for each concerned taxon, the corresponding ontology of developmental stages (if such an ontology exists) and the corresponding bridge files.</p> <p>For example, the <code>collected-drosophila.owl</code> ontology is the result of merging:</p> <ul> <li>Uberon,</li> <li>CL,</li> <li>the Drosophila Anatomy Ontology (FBbt),</li> <li>the bridge between Uberon and FBbt,</li> <li>the bridge between CL and FBbt,</li> <li>the Drosophila Developmental Ontology (FBdv),</li> <li>and the bridge between Uberon and FBdv.</li> </ul> <p>Note: Collected ontologies used to be called \u201cimporter ontologies\u201d, because they were made by using OWL <code>Import</code> statements to gather the different component ontologies. This no longer reflects how those ontologies are built (see further below for some details about the pipeline that builds them), so \u201ccollected ontologies\u201d is now preferred.</p>"},{"location":"combined_multispecies/#available-collected-ontologies","title":"Available collected ontologies","text":"<p>Uberon defines several collected ontologies for different taxonomic levels. The custom Uberon Makefile, in its \u201cComposite pipeline\u201d section, is the definitive source of truth for the various collected ontologies that are available, but as of January 2025 the list is as follows (for simplicity, bridge files are not mentioned):</p> Product Components collected-drosophila FBbt + FBdv collected-worm WBbt + WBls collected-zebrafish ZFA collected-xenopus XAO collected-human EHDAA2 + AEO collected-mouse EMAPA + MmusDv collected-adult-mammal MA collected-embryonic-mammal collected-human + collected-mouse collected-mammal collected-adult-mammal + collected-embryonic-mammal + DHBA + DMBA + HBA + MBA + PBA collected-anamniote collected-zebrafish + collected-xenopus collected-amniote collected-mammal collected-tetrapod collected-amniote + collected-xenopus collected-vertebrate collected-tetrapod + collected-zebrafish collected-metazoan collected-vertebrate + collected-drosophila + collected-worm + CEPH + CTENO + PORO collected-lifestages Uberon\u2019s life-stages subset + all available species-specific life stages ontologies <p>Note that only <code>collected-metazoan</code>, <code>collected-vertebrate</code>, and <code>collected-lifestages</code> are regularly built and provided as release artifacts, available through permanent URLs in OBO, OWL, and Obograph-JSON formats. Other products, if they are needed, must be built on demand (see further below for instructions on how to do that).</p>"},{"location":"combined_multispecies/#advantages","title":"Advantages","text":"<p>Collected ontologies</p> <ul> <li>retain all logical and non-logical axioms of the source ontologies;   reasoning \u201cjust works\u201d;</li> <li>allow incorporation at desired level of granularity.</li> </ul>"},{"location":"combined_multispecies/#disadvantages","title":"Disadvantages","text":"<ul> <li>Collected ontologies are highly latticed and difficult to navigate.</li> <li>Differences between a species classand the Uberon parent is often   trivial or non-existent, resulting in duplicated portions of the   hierarchy.</li> <li>Many tools are not configured to show the \u201cOBO Foundry unique label\u201d   provided by the bridge files, which means that for example   <code>collected-metazoan.owl</code> will display 10 or so classes with a   <code>rdfs:label</code> of \u201cbrain\u201d.</li> </ul>"},{"location":"combined_multispecies/#composite-ontologies","title":"Composite ontologies","text":"<p>Composite ontologies were designed to address the redundancy problems inherent with collected ontologies.</p>"},{"location":"combined_multispecies/#principle","title":"Principle","text":"<p>A composite ontology is derived from the corresponding collected ontology (for example, <code>composite-drosophila</code> is derived from <code>collected-drosophila</code>). The key part of the process by which a composite ontology is derived is to replace, whenever possible, the taxon-specific terms coming from the taxon-specific ontologies by anonymous class expressions that use the corresponding taxon-neutral term from Uberon.</p> <p>For example, let us consider the FBbt term \u201covary\u201d (<code>FBbt:00004865</code>): it is mapped to the Uberon term \u201covary\u201d (<code>UBERON:0000992</code>), which means that <code>collected-drosophila</code> contains the following axiom (provided by the bridge between Uberon and FBbt):</p> <pre><code>FBbt:00004865 EquivalentTo: UBERON:0000992 and (in_taxon some NCBITaxon:7227)\n</code></pre> <p>(<code>NCBITaxon:7227</code> being the identifier for the Drosophila melanogaster taxon).</p> <p>To produce <code>composite-drosophila</code>, we remove the <code>FBbt:00004865</code> class, and rewrites all axioms that refer to it to make them use the anonymous expression the class is equivalent to instead.  So the following axiom, which states that the \u201coviduct\u201d (<code>FBbt:00004911</code>) is continuous with the fly ovary:</p> <pre><code>FBbt:00004911 SubClassOf: continuous_with some FBbt:00004865\n</code></pre> <p>gets rewritten as</p> <pre><code>FBbt:00004911 SubClassOf: continous_with some (UBERON:00009992 and (in_taxon some NCBITaxon:7227))\n</code></pre> <p>The figure below illustrates the resulting differences between a collected ontology and a composite ontology. On the left, the collected-drosophila ontology contains, below the taxon-neutral \u201covary\u201d (<code>UBERON:0000992</code>) term, the fly-specific \u201covary\u201d term (<code>FBbt:00004865</code>), to which all terms related to the Drosophila ovary are attached. On the right, the composite-drosophila no longer contains the redundant fly-specific \u201covary\u201d, and all the fly terms are directly rattached to the taxon-neutral \u201covary\u201d.</p> <p></p>"},{"location":"combined_multispecies/#available-composite-ontologies","title":"Available composite ontologies","text":"<p>Because composite ontologies are derived from the collected ontologies, each collected ontology has a corresponding composite ontology. Therefore, you may refer to the list of collected ontologies above.</p> <p>As for the collected ontologies, only <code>composite-metazoan</code>, <code>composite-vertebrate</code>, and <code>composite-lifestages</code> are built regularly and provided as pre-built artifacts. Other products, if they are needed, must be built on demand.</p>"},{"location":"combined_multispecies/#advantages-and-disadvantages","title":"Advantages and disadvantages","text":"<p>Compared to collected ontologies, composite ontologies have less redundancy and are easier to navigate.</p> <p>However, the absence of some taxon-specific terms (when a taxon-neutral equivalent is available) may make them unsuitable for data annotation, unless the taxon information is recorded separately. For example, if you need to annotate a fly ovary sample, a composite ontology will not contain a term that specifically represents a fly ovary \u2013 it will only contain a term that represents a taxon-neutral ovary, and you will need another way to record the fact that the sample is coming from a fruit fly.</p>"},{"location":"combined_multispecies/#building-the-multi-species-ontologies","title":"Building the multi-species ontologies","text":"<p>Collected ontologies are simply a merge (performed using ROBOT\u2019s <code>merge</code> command) of the source ontologies.</p> <p>The only particularity is that the taxon-specific ontologies are not fetched directly from their canonical online locations. Instead, they are mirrored locally, the mirrors are committed to the repository, and all subsequent operations are done using the local mirrors. To refresh the local mirrors, run the following command from the <code>src/ontology</code> directory:</p> <pre><code>sh run.sh make MIR=true IMP=true all_local_imports\n</code></pre> <p>(Alternatively you may also run <code>sh run.sh make refresh-external-resources</code> instead, which will also the mappings and the bridge files, as well as the normal ODK import modules.)</p> <p>To build a given collected ontology, simply run:</p> <pre><code>sh run.sh make tmp/collected-&lt;name&gt;.owl\n</code></pre> <p>A composite ontology is built by first building the corresponding collected ontology, then</p> <ul> <li>removing all disjointness axioms;</li> <li>removing redundant taxon-specific terms as explained above (this is   done using a custom ROBOT plugin);</li> <li>reasoning, relaxing, and reducing.</li> </ul> <p>To build a given composite ontology, simply run:</p> <pre><code>sh run.sh make composite-&lt;name&gt;.owl\n</code></pre>"},{"location":"combined_multispecies/#adding-a-species-to-a-collectedcomposite-ontology","title":"Adding a species to a collected/composite ontology","text":"<p>(This is not an exhaustive documentation, but intended as a rough guide for future reference.)</p> <ol> <li>Add a \u201clocal mirror\u201d for the species-specific ontology to be    included. Follow the examples of the Makefile rules for the existing    local mirrors.</li> <li>Ensure that mappings between Uberon/CL terms and the species-specific    terms are available -- either maintained in Uberon directly, or    fetched from a remote source (likely the species-specific ontology).</li> <li>Add a bridge file (or several bridges, if needed) for    the species-specific ontology.</li> <li>Add the local mirror and any corresponding bridge file to the list of    source files in the <code>COLLECTED_xxx_SOURCES</code> variable (where <code>xxx</code> is    the name of the collected/composite ontology, e.g. <code>metazoan</code>).</li> </ol>"},{"location":"contributing/","title":"How to contribute to Uberon","text":""},{"location":"contributing/#how-to-contribute-to-uberon","title":"How to contribute to UBERON","text":""},{"location":"contributing/#github-tracker","title":"GitHub Tracker","text":"<p>Our preferred way of receiving requests for new terms, changes to the ontology or questions is by creating a new issue using our issue tracker:</p> <ul> <li>Current list of issues</li> <li>Submit a new issue</li> </ul>"},{"location":"contributing/#mailing-list","title":"Mailing List","text":"<p>The obo-anatomy mail list is a community listserve for all anatomical ontologies: - Subscribe via google groups</p>"},{"location":"contributing/#follow-us","title":"Follow us","text":"<ul> <li>Twitter</li> </ul>"},{"location":"current_release/","title":"Canonical release","text":"<p>The latest canonical release is always available at http://purl.obolibrary.org/obo/uberon.owl.</p> <p>Versions in OBO format and OBOGraph JSON are also available.</p>"},{"location":"current_release/#variants","title":"Variants","text":"<ul> <li><code>uberon-base</code>:   OWL,                    OBO,                    JSON</li> <li><code>uberon-full</code>:   OWL,                    OBO,                    JSON</li> <li><code>uberon-simple</code>: OWL,                    OBO,                    JSON</li> <li><code>uberon-basic</code>:  OWL,                    OBO,                    JSON</li> </ul> <p>Please refer to the OBOOK for an explanation of what those variants are.</p>"},{"location":"current_release/#multi-species-ontologies","title":"Multi-species ontologies","text":"<ul> <li><code>collected-metazoan</code>:   OWL,   OBO,   JSON</li> <li><code>composite-metazoan</code>:    OWL,   OBO,   JSON</li> <li><code>composite-metazoan-basic</code>:   OWL,   OBO,   JSON</li> <li><code>composite-vertebrate</code>:   OWL,   OBO,   JSON</li> <li><code>composite-vertebrate-basic</code>:   OWL,   OBO,   JSON</li> </ul> <p>Please refer to our multi-species ontologies page for an explanation of what we call a \u201ccollected\u201d or a \u201ccomposite\u201d ontology.</p> <p>Note that the bridge files, used to merge Uberon/CL with the taxon-specific ontologies, are treated as intermediate products and are not available as release artifacts. Consequently, they must be obtained directly from the GitHub repository. The mappings from which the bridges are derived are available as a SSSOM file.</p>"},{"location":"current_release/#subsets","title":"Subsets","text":"<ul> <li><code>common-anatomy</code>:   OWL,   OBO,   JSON</li> <li><code>cumbo</code>:   OWL,   OBO,   JSON</li> </ul>"},{"location":"current_release/#taxon-specific-subsets","title":"Taxon-specific subsets","text":"<ul> <li><code>amniote-basic</code>:   OWL,   OBO,   JSON</li> <li><code>euarchontoglires-basic</code>:   OWL,   OBO,   JSON</li> <li><code>human-view</code>:   OWL,   OBO,   JSON</li> <li><code>mouse-view</code>:   OWL,   OBO,   JSON</li> <li><code>xenopus-view</code>:   OWL,   OBO,   JSON</li> </ul>"},{"location":"current_release/#topic-specific-subsets","title":"Topic-specific subsets","text":"<ul> <li><code>appendicular-minimal</code>:   OWL,   OBO,   JSON</li> <li><code>circulatory-minimal</code>:   OWL,   OBO,   JSON</li> <li><code>cranial-minimal</code>:   OWL,   OBO,   JSON</li> <li><code>digestive-minimal</code>:   OWL,   OBO,   JSON</li> <li><code>excretory-minimal</code>:   OWL,   OBO,   JSON</li> <li><code>immune-minimal</code>:   OWL,   OBO,   JSON</li> <li><code>musculoskeletal-minimal</code>:   OWL,   OBO,   JSON</li> <li><code>nephron-minimal</code>:   OWL,   OBO,   JSON</li> <li><code>nervous-minimal</code>:   OWL,   OBO,   JSON</li> <li><code>pulmonary-minimal</code>:   OWL,   OBO,   JSON</li> <li><code>renal-minimal</code>:   OWL,   OBO,   JSON</li> <li><code>reproductive-minimal</code>:   OWL,   OBO,   JSON</li> <li><code>sensory-minimal</code>:   OWL,   OBO,   JSON</li> </ul>"},{"location":"history/","title":"A brief history of UBERON","text":"<p>The following page gives an overview of the history of UBERON.</p> <p>See Monarch Seminar Series: The Uberon Anatomy Ontology (2024) slides (1), slides (2).</p>"},{"location":"id-management/","title":"ID management in Uberon","text":""},{"location":"id-management/#temporary-ids","title":"Temporary IDs","text":"<p>\u201cTemporary IDs\u201d are an experimental mechanism to allow editors to mint new term IDs without worrying about potential conflicting IDs.</p> <p>This is primarily intended for AI agents, which are likely to open many PRs in parallel but have to share a single ID range (contrary to human editors, who all have their own range) and have no way of keeping track of which IDs are being used in concurrent PRs (again contrary to human editors, who can rely on Prot\u00e9g\u00e9 for that).</p> <p>However temporary IDs are in no way restricted to AI agents, and any editor could use them if they so want. For example, they could be useful for an external, occasional editor \u2013\u00a0someone who is not a known contributor to Uberon and for whom we may not necessarily want to allocate a dedicated ID range.</p>"},{"location":"id-management/#editing-the-ontology-with-temporary-ids","title":"Editing the ontology with temporary IDs","text":"<p>From an editor\u2019s point of view, all that is needed to use temporary IDs is to use the <code>Temporary IDs</code> range defined in the <code>uberon-idranges.owl</code> file.</p> <p>For editors using Prot\u00e9g\u00e9, this means selecting said <code>Temporary IDs</code> range when Prot\u00e9g\u00e9 asks you to select an ID range policy, just after having opened the Uberon edit file.</p> <p>For other editors (including AI agents), this means making sure that whenever a new ID is needed, it is generated within the range allocated to <code>Temporary IDs</code> (it should normally be <code>UBERON:99NNNNN</code>, but please check the contents of the <code>uberon-idranges.owl</code> file, just in case the range is changed in the future).</p>"},{"location":"id-management/#replacing-temporary-ids-with-definitive-ids","title":"Replacing temporary IDs with definitive IDs","text":"<p>Replacing temporary IDs with definitive IDs is done by invoking the <code>allocate-definitive-ids</code> target:</p> <pre><code>sh run.sh make allocate-definitive-ids\n</code></pre> <p>This will find all temporary IDs within the ontology and replace them with newly allocated definitive IDs picked from within the <code>Automation</code> range defined in the <code>uberon-idranges.owl</code> file. All axioms that were referring to temporary IDs will be automatically re-written so that they refer to the corresponding newly allocated definitive IDs.</p> <p>This replacement must be performed at the latest possible stage, just before a PR is merged. If temporary IDs in a PR are replaced by definitive IDs, and the PR is then left unmerged for a while, then ID conflicts may occur when the PR is finally merged.</p> <p>For convenience, a GitHub Actions workflow is available to perform the ID replacement step on a PR without requiring a Uberon maintainer to check out the PR and invoke the <code>allocate-definitive-ids</code> manually. When a PR containing temporary IDs has been deemed OK for merging, a maintainer should trigger the <code>allocate-definitive-ids</code> GitHub Actions workflow on the PR\u2019s branch, wait for that workflow to terminate (it should take a couple of minutes at most), and then immediately merge the PR.</p>"},{"location":"id-management/#automatic-replacement-of-temporary-ids-upon-pushing-to-master","title":"Automatic replacement of temporary IDs upon pushing to master","text":"<p>Alternatively, a PR containing temporary IDs can be merged \u201cas is\u201d to the master branch. This will then trigger an automatic ID replacement operation (made by the same <code>allocate-definitive-ids</code> GitHub Actions workflow), directly on the master branch.</p> <p>Compared to the approach above, where the ID replacement is done on the PR prior to merging, this approach has the following advantages:</p> <ul> <li>it is entirely automated, and does not require any manual intervention   from a maintainer;</li> <li>it eliminates the risk of an ID conflict still occurring between the   moment IDs are replaced on a PR and the moment the PR is merged.</li> </ul> <p>It has the inconvenient that it lets temporary IDs becoming part of the history of the master branch, which may make perusing the history more cumbersome as the history will be \u201cpolluted\u201d by commits that do nothing more than rewriting IDs. With the \u201creplace-before-merging\u201d approach, such commits can be made invisible if the PR is small enough to allow for a \u201csquash merge\u201d instead of a normal merge \u2013\u00a0then only the definitive IDs will only ever make it to the master branch.</p>"},{"location":"old_releases/","title":"Releases prior to migration to GitHub","text":"<p>The releases prior to October 2020 can be found here.</p>"},{"location":"onboarding/","title":"On-boarding new Uberon curators","text":"<p>This document is intended as a quick checklist that existing curators can follow to ensure that new curators are provided with the informations and the access that they need in order to start working with Uberon.</p> <ol> <li>Invite them to the Anatomy and Cell    Ontologies Slack workspace.</li> <li>Invite them to the OBO Community    Slack workspace and point them to the <code>#uberon</code> channel.</li> <li>Add them to the meeting invites on the Monarch Calendar (FIXME: How    to do that? Who is the person to contact?)</li> <li>Add their names to the table in the docs/team.md page.</li> <li>Invite them to the Uberon/CL curators GitHub team.</li> <li>Assign an ID range to each of them and add the ranges to the    <code>src/ontology/uberon-idranges.owl</code> file.</li> <li>Point them to the relevant documentation, especially<ul> <li>Ontology Curator Pathway, GO-style,</li> <li>Contributing to OBO ontologies,</li> <li>Standard Operating Procedures for Uberon Curators.</li> </ul> </li> </ol>"},{"location":"team/","title":"The Uberon/CL Team","text":"<p>The Uberon team is responsible for managing the Uberon project. It usually comprises a number of professional ontology editors hired by various projects with an anatomy ontology component, a number of OBO volunteers and various stakeholders. Due to their closeness, the Uberon and CL ontologies are managed by the same team. See also the GitHub contributor list.</p>"},{"location":"team/#current-uberoncl-team","title":"Current Uberon/CL Team","text":"Name (GitHub) Funding Information FTEs Associated teams Role Responsibilities David Osumi-Sutherland (@dosumis) HuBMAP, Phenomics First some Editors Lead Coordination, Strategy Chris Mungall (@cmungall) Phenomics First 0 Editors Lead Coordination, Strategy, TCs/Orphan taxa/evolutionary variability Aleix Puig HuBMAP 0 Editors Ontology Editor Editing for HuBMAP and as issues require Alex Diehl 0 Editors Ontology Editor Immune cells Alida Avola (@AvolaAmg) BICAN/HMBA 0 Editors Ontology Editor Brain/nervous system, new term requests for BICAN Anita Caron (@anitacaron) 0.2 Editors Ontology Pipeline Developer Bulk Edits, Quality Control, Pipeline. Caroline Eastwood (@Caroline-99) CZI 0 Editors Ontology Editor New term requests for CELLxGENE Ceri Van Slyke (@cerivs) ZFIN 0 Editors Ontology Editor ZFA-Uberon mappings. Chuan Xu 0 Editors Ontology Editor Damien Goutte-Gattat (@gouttegd) FlyBase 0 Editors Ontology Pipeline Developer FBbt-Uberon mappings, legacy pipelines extermination Ellen M Quardokus (@emquardokus) HuBMAP 0 Editors Ontology Editor Human Biomolecular Atlas Program (HuBMAP) new term requests. Jasmine Belfiore (@JABelfiore) CAP 0 Editors Ontology Editor New term requests for CAP/HCA/HDCA Jim Balhoff (@balhoff) 0 Editors Ontology Editor External advisor. Joshua Fortriede 0 Editors Ontology Editor Meghan Balk (@megbalk) 0 Editors Ontology Editor Nico Matentzoglu (@matentzn) Phenomics First 0 Editors Ontology Pipeline Developer Bulk Edits, Quality Control, Pipeline. Nicole Vasilevsky (@nicolevasilevsky) Phenomics First 0 Editors Ontology Editor Edits needed for Mondo or uPheno. Paola Roncaglia (@paolaroncaglia) Human Cell Atlas some Editors Principal Ontology Editor Editing cell type terms needed for single-cell projects (Human Cell Atlas (HCA), Single Cell Expression Atlas, etc.) Patrick Ray 0 Editors Ontology Editor Editing Neurons and brain related terms. Ray Stefancsik (@rays22) Phenomics First 0.2 Editors Principal Ontology Editor Editing; Tickets needed for the Phenotype Reconciliation Effort; Documentation. Sabrina Toro (@sabrinatoro) Phenomics First 0 Editors Ontology Editor Edits needed for Mondo or uPheno. Shawn Tan (@shawntanzk) 0 Editors Ontology Pipeline Developer, Ontology Editor Editing Neurons and brain related terms. Tiago Lubiana Alves (@lubianat) 0 Editors Ontology Editor New Term Requests. Wasila Dahdul (@wdahdul) 0 Editors Ontology Editor External advisor. Yvonne Bradford (@ybradford) ZFIN 0 Editors Ontology Editor ZFA-Uberon mappings."},{"location":"team/#past-team-members-and-major-contributors","title":"Past team members and major contributors","text":"<ul> <li>Melissa Haendel (@mellybelly)</li> <li>Maria Keays (@mkeays)</li> <li>Tom Gillespie (@tgbugs)</li> </ul>"},{"location":"uberon-editor-sop/","title":"Standard Operating Procedure for Uberon Curators","text":"<p>Note: This document is meant to only contain Uberon specific SOPs, for general ontology editing SOPs, please refer to the obook</p>"},{"location":"uberon-editor-sop/#introduction","title":"Introduction","text":"<p>For context on why we have these SOPs, it is useful to have a basic understanding of the history and scope of Uberon. Uberon was seeded via a merge of many major anatomy ontologies, covering many different species, followed by a mix of programmatic approaches and curation to produce a consensus representation.  As a result, most terms have many xrefs to source anatomy ontologies and many retain the original definitions in these source ontologies as 'external definition'.  This can be useful in understanding cross-species use.  Many terms also have homology notes which can be useful for this.  </p> <p>The broad cross-species nature of Uberon means that care needs to be taken to avoid adding  axioms that apply to a limited number of species to taxonomically broad terms with assertions. If the term is a high level classification in Uberon, the results of getting this wrong can be significant.  For example, given a knowledge of vertebrate neural development, you might be tempted to add a develops_from between brain and neural tube. Adding this would result in changed entailments for 1000s of terms across multiple ontologies - all neurons in CL, many developmental terms in GO.  But this would be wrong, as the term brain applies to invertebrates as well as vertebrates, and invertebrates do not have a neural tube.</p>"},{"location":"uberon-editor-sop/#taxon-restrictions","title":"Taxon Restrictions","text":"<p>Uberon is a cross-species ontology, and editors should be careful when adding taxon restrictions. Terms added to Uberon should be as taxonomically broad as possible, and taxon restrictions should be used carefully. Before adding any taxon restrictions, make sure go through this guide and understand the implications of the taxon restriction and how to properly add them.</p>"},{"location":"uberon-editor-sop/#relations-guide","title":"Relations Guide","text":"<p>The following is a guide for relations to use with some notes and examples. This is not a comprehensive list and will be continually worked on, however, it contains some of the more common relations used in Uberon. Do familiarise yourself with them and use this section as a reference when you are adding relations. (Should we add something here to direct to DOSDP patterns that Chris generated with the patterniser? It is a bit more complicated to explain that but here's the folder)</p>"},{"location":"uberon-editor-sop/#overlaps","title":"overlaps","text":"<p>If an anatomical structure have some part in common, but not fully part_of, another structure, we use <code>overlaps</code>.</p> <p>Example: olfactory system subclassOf 'overlaps' some 'nervous system'.</p> <p>means that</p> <ol> <li>Part of the olfactory system is part of the nervous system. We wouldn't say 'olfactory system part_of some nervous system' as there are parts of the olfactory system that would not be considered the nervous system.</li> <li>Not all parts of the olfactory system is part of the nervous system. We wouldn't say 'olfactory gland overlaps some olfactory system' as all of the olfactory gland is considered as part of the olfactory system. (note: this is not wrong logically, but a more precise part_of should be used instead)</li> <li>Part of olfactory system are part of the nervous system at all times. If something, for example, develops and migrates out of the structure, we do not use overlaps. (see develops_from instead). </li> </ol>"},{"location":"uberon-editor-sop/#part-of","title":"part of","text":"<p>We record anatomical location using <code>part of</code>. This means that subject is fully part_of the object.  This relation is a subclassOf overlaps, but is used in cases where the subject is fully part_of the object.</p> <p>Example:  brain endothelium subclassOf 'part of' some 'brain'.</p> <p>means that </p> <ol> <li>All of the brain endothelium is part of the brain. We wouldn't say 'endothelium part_of some brain' as not all endothelium are part of the brain. </li> <li>All parts of the brain endothelium are part of the brain (e.g. all cells that are part_of the brain endothelium are also cells that are part_of the brain) </li> <li>Brain endothelium are part_of some brain at all times. (Makes more of a difference for cells being part of anatomical structure, e.g. a blood cell is not part_of the brain endothelium because it moves out of the brain endothelium.)</li> </ol> <p>Related Equivalence Pattern: X_part_of_X</p>"},{"location":"uberon-editor-sop/#has-part","title":"has part","text":"<p>The inverse of part of.  In Uberon, preference should be given to using part_of rather that has_part.</p>"},{"location":"uberon-editor-sop/#contributes-to-morphology-of","title":"contributes to morphology of","text":"<p>If two entities overlap in a way that a change in morphology in the subject would entail a change of morphology in the object. </p> <p>Examples: every skull contributes to morphology of the head which it is a part of.  Counter-example: nuclei do not generally contribute to the morphology of the cell they are part of, as they are buffered by cytoplasm.</p>"},{"location":"uberon-editor-sop/#develops-from","title":"develops from","text":"<p>We record development using the relation <code>develops from</code>. </p> <p>Example: spinal cord subclassOf 'develops from' some 'prosterior neural tube'</p> <p>means that</p> <ol> <li>The spinal cord directly develops from the prosterior neural tube</li> <li>Given that <code>develops from</code> is transitive, and that the prosterior neural tube develops from some the chordal neural plate, the spinal cord is implied to develop from the chordal neural plate. </li> </ol> <p>Note: <code>develops from</code> does not necessarily the subject directly develops from the object, for example, having <code>'spinal cord' subclassOf 'develops from' some 'chordal neural plate'</code> is not wrong. You should however strive to get the most direct object and let the inference do the work in linking it to earlier developmental stages. </p>"},{"location":"uberon-editor-sop/#defined-classes","title":"Defined Classes","text":"<p>Sometimes it is useful to define a grouping classes that automatically classify other terms, for example the term \"small intestine Peyer's patch\" has a logical definition that can be used to automatically classify terms for Peyer's patch in various parts of the small intestine (duodenum, ilium etc). In these case, it is important to use an established pattern (or to extend the established patterns if this is needed).  Established patterns are documented in DOSDP templates  - see: &lt; add link to templates or to MD doc generated from them&gt;</p>"},{"location":"uberon-editor-sop/#cross-references-to-the-literature","title":"Cross-references to the literature","text":"<p>Assertions in textual definitions, evidence provided in comments, and synonyms should be backed up by citing the appropriate literature.</p> <p>Citations are made by cross-references, that is by adding <code>http://www.geneontology.org/formats/oboInOwl#hasDbXref</code> annotations to the definition, comment, and synonym annotations. Add one such annotation per reference, using the CURIE syntax with well-known prefixes:</p> <ul> <li><code>PMID:1234567</code> for a PubMed identifier;</li> <li><code>doi:xx.yyyy/...</code> for a DOI;</li> <li><code>ISBN:...</code> for a ISBN.</li> </ul> <p>If the main source for an assertion is a term in another ontology, the short identifier for that term may be used as a cross-reference. For example, <code>WBbt:0006799</code> to cross-reference a term in the C. elegans Gross Anatomy Ontology.</p> <p>If using a MeSH (Medical Subject Heading) term as a cross-reference, add the database_cross_reference annotation using the MeSH Unique ID, NOT MeSH Tree Number. For example, a database_cross_reference can be MESH:D054326, NOT MESH:A07.015.908.194.500.</p> <p>ORCID identifiers may also be used when the only available source for an assertion is an individual researcher. This should be done sparingly.</p> <p>Technical details of adding a cross-reference using Prot\u00e9g\u00e9:</p> <p>For CURIEs, ORCIDs: In the \"Create Annotation\" window, select the annotation property database_cross_reference. For adding URLs to text definitions or synonyms:  In the \"Create Annotation\" window, select the annotation property database_cross_reference. For adding URLs to axioms that are NOT text definitions or synonyms:  In the \"Create Annotation\" window, select the annotation property source.</p> <p>For CURIEs: Enter the CURIE, using the bioregistry OBO context prefix (link to prefixmap), as a Value on the \"Literal\" tab. Leave Datatype empty.</p> <p>In cases where more than one CURIE is available for a resource, either is acceptable, but using the more semantically specific identifier is recommended. For example, when both a PMID and a doi are available for a resource, using the PMID is recommended since it indicates the cross-reference points to a paper, as opposed to a doi which could point to any digital object.</p> <p>For ORCIDs: Enter the ORCID as an IRI in the IRI field on the \"IRI Editor\" tab, for example <code>https://orcid.org/0000-0002-7356-1779</code>.</p> <p>For URLs: Enter the URL as a literal string. Note: In OWL-based files (like cl-edit.owl), Datatype <code>xsd:anyURI</code> is also selected; however, in OBO-based files (like uberon-edit.obo) these always become strings, so no selection needs to be made for Datatype in Uberon. Datatype selection is planned to be implemented in a future OBO revision, and updates can be checked at https://github.com/owlcollab/oboformat/issues/128. NOTE: URLs should be avoided when a cross-reference with a CURIE is otherwise available.</p> <p>To restate, in all cases above except ORCIDs, the values are entered as literal strings. An ORCID MUST BE entered as an IRI.</p>"},{"location":"uberon-editor-sop/#synonyms","title":"Synonyms","text":"<p>Extensive addition of synonyms helps \u201cfindability\u201d of terms when searching. Synonyms can and should be added liberally. Of note, the intention of the ontology is not meant to record how a synonym is used in all specific sources in which it appears. Rather an editor, after doing due diligence in researching the terms/synonyms, must determine how a term is used at the present moment in the scientific community.</p> <p>Guidelines on the type of synonyms:</p> <ol> <li>Use an exact synonym only when the label and the synonym can be used interchangeably without dispute and refer to the same concept. </li> </ol> <p>Example: the terms \u201caorta wall\u201d, \u201caortic wall\u201d and \u201cwall of aorta\u201d all refer to the exact same concept and would be considered exact synonyms. Terms that may refer to other concepts, especially within the biomedical domain, should not be annotated as exact synonyms, including abbreviations. </p> <ol> <li>A synonym that is an abbreviation should be annotated as a related synonym and with property type \u201cabbreviation\u201d (technically: the synonym annotation assertion axiom should itself be annotated with a <code>http://www.geneontology.org/formats/oboInOwl#hasSynonymType</code> property with value <code>http://purl.obolibrary.org/obo/OMO_0003000</code>). </li> </ol> <p>Example: \u201cBA\u201d is a related synonym for both 'basilar artery' and 'bed nucleus of the accessory olfactory tract' at the time of this writing. Additionally, within the biomedical domain, it can also represent 'brachial artery' or 'Bone Age', two other distinct concepts with separate OBO ontology terms.</p> <ol> <li> <p>Exact synonyms should be unique across the ontology. In other words, if class A has synonym \u201cX\u201d, \u201cX\u201d should not be an exact synonym for any other Uberon term.</p> </li> <li> <p>Be mindful of the \u201cdirectionality\u201d of the narrow and broad types of synonyms. They qualify the synonym, not the original term. </p> </li> </ol> <p>Example: stating that \u201ctrunk wall\u201d is a narrow synonym of 'body wall' means that \u201ctrunk wall\u201c refers to a narrower (i.e., more specific) concept than 'body wall', not the other way around.</p> <ol> <li> <p>The related synonym type should be used for cases where the overlap between the synonym and the term label may be unclear, disputable or not true in all scenarios or contexts, but you want the term to be findable when searching. This includes abbreviations, which should be annotated as related synonyms with synonym type \u201cabbreviation\u201d (see point 1 above).</p> </li> <li> <p>If a synonym includes a mix of abbreviations and words, the annotation property 'has related synonym' with has_synonym_type \"abbreviation\" should still be used unless there is enough context within the synonym itself to make it clear that the synonym refers only to the concept being annotated.</p> </li> </ol> <p>Example: \u201cDG granule cell layer\u201d would be an exact synonym of 'dentate gyrus granule cell layer', even though \u201cDG\u201d (in this case) is an abbreviation for \u201cdentate gyrus\u201d. Note that without this context \u201cDG\u201d should not be considered an exact synonym for \"dentate gyrus\" as \u201cDG\u201d could also mean, among many things, the CHEBI term \"DG\" (7-deazaguanine).</p> <p>Compare the previous example to \u201cEC layer 1\u201d, which should be a related synonym (with synonym type \"abbreviation\") of 'entorhinal cortex layer 1', where there is not enough context to confidently determine what \"EC\" stands for.</p>"},{"location":"uberon-editor-sop/#design-pattern-usage-with-dosdp","title":"Design Pattern Usage with DOSDP","text":"<p>The Uberon ontology is composed of a large number of terms, classifications and relationships, which continue to increase. As maintaining manually all these classifications and relationships would be an arduous task, a substantial portion of the maintenance is automated. This automation depends, to a significant extent, on the systematic application of design patterns.</p> <p>Uberon uses Dead simple OWL design patterns (DOSDP, Osumi-Sutherland et al., 2017) to document simple patterns, as they require minimal programming expertise, and once implemented, it is easy to edit.</p> <p>All patterns are stored in /src/patterns/dosdp-patterns, while the editable tables are located in /src/patterns/data/default.</p>"},{"location":"uberon-editor-sop/#connecting-vessels","title":"Connecting vessels","text":"<p>Pattern name: vessel_connecting_branch_of_vessel_pattern.yaml</p> <p>Blood and lymphatic vessels are tubes that convey body fluids through the tissues and organs, forming branching or networked structures. The relation between a vessel and its branches can be recorded in several ways:</p> <ul> <li>RO:0002375\u00a0in branching relationship with<ul> <li>RO:0002252\u00a0connecting branch of</li> <li>RO:0002253\u00a0has connecting branch</li> <li>RO:0002377\u00a0distributary of<ul> <li>RO:0002378\u00a0anabranch of</li> </ul> </li> <li>RO:0002380\u00a0branching part of</li> <li>RO:0002381\u00a0main stem of</li> <li>RO:0002569 has branching part</li> </ul> </li> </ul> <p>However, while it is useful to have this wide range of object properties to record relations between branches, it can also lead to selecting a property that does not accurately reflect the relationship between subject and object. An example of this is the misuse of 'branching part of', which is a subclass of 'part of', but it has been used extensively for branches that are no longer part of the stem.</p> <p>Therefore, we need standarization for how branching relationships should be recorded in Uberon. The object property 'connecting branch of' is a subproperty of 'connected to' and should be used to describe the relation between a branching vessel and the stem vessel. Ex:</p> <p>'axillary artery' SubClassOf 'connected to' some 'subclavian aretery'</p>"},{"location":"uberon-editor-sop/#general-tips","title":"General Tips","text":"<p>Changes to classifications of terms from the 2x, 3x and 4x range, or anything higher up in the hierarchy (e.g. 2 levels above leaf nodes) can create unintended consequences to the ontology (e.g. due to , and it\u2019s best to get a senior ontologist to review (e.g. @cmungall)</p> <p>Don\u2019t trust a term to mean what you expect by the label alone. Make sure you look at the textual and logical definition of terms instead of taking the label at face value. </p> <p>Look at the reasoned diff (This is automatically generated in a GitHub actions when you create a PR)- huge changes in reasoned diff should be looked through carefully to ensure the changes are all intended.</p> <p>Keep in mind that uberon is taxonomically very broad and so it is important to make sure you don\u2019t add axioms that apply to a limited number of species to taxonomically broad terms. </p>"},{"location":"uberon-release/","title":"Uberon Release workflow","text":"<p>While Uberon is an ODK ontology, it has a specific workflow for releases due to its large size and the limitations on standard GitHub releases.</p>"},{"location":"uberon-release/#requirements","title":"Requirements","text":"<p>Aside from the standard requirements needed for ODK workflow, <code>GH</code> is required.  Instructions on how to install <code>GH</code> can be found here</p> <p>You will need to log in to your GitHub account on <code>GH</code> before you can uses it. To do this, enter the following in your terminal: <pre><code>gh auth login\n</code></pre></p> <p>You can then follow instructions below for web browser login (or use your prefer means of logging in). <pre><code>% gh auth login\n? What account do you want to log into? GitHub.com\n? What is your preferred protocol for Git operations? SSH\n? Generate a new SSH key to add to your GitHub account? Yes\n? Enter a passphrase for your new SSH key (Optional) \n? Title for your SSH key: GitHub SSH\n? How would you like to authenticate GitHub CLI? Login with a web browser\n\n! First copy your one-time code: XXXX-XXXX\nPress Enter to open github.com in your browser... \n\u2713 Authentication complete.\n- gh config set -h github.com git_protocol ssh\n\u2713 Configured git protocol\n\u2713 Uploaded the SSH key to your GitHub account: /Users/username/.ssh/id_ed25519.pub\n\u2713 Logged in as username\n</code></pre></p>"},{"location":"uberon-release/#release-process","title":"Release Process","text":""},{"location":"uberon-release/#preparation","title":"Preparation","text":"<p>Preparation:</p> <ol> <li>Ensure that all your pull requests are merged into your main (master) branch</li> <li>Make sure that all changes to master are committed to Github (<code>git status</code> should say that there are no modified files)</li> <li>Locally make sure you have the latest changes from master (<code>git pull</code>)</li> <li>Checkout a new branch (e.g. <code>git checkout -b release-2021-01-01</code>)</li> <li>You may or may not want to refresh your imports as part of your release strategy (see here)(Note: in UBERON we decouple our imports and releases - we hence advice that you do not update imports)</li> <li>Make sure you have the latest ODK installed by running <code>docker pull obolibrary/odkfull</code></li> </ol> <p>To actually run the release, you:</p> <ol> <li>Open a command line terminal window and navigate to the src/ontology directory (<code>cd uberon/src/ontology</code>)</li> <li>Run the release using <code>sh run.sh make uberon DEPLOY_GH=false</code>. This will build all files and copy them to the correct place. (Note: the <code>IMP=false</code> is used to decouple imports refresh with release)</li> <li>Review the release as per the <code>review release</code> section in ODK-workflow release document</li> <li>Create a pull request and get a second set of eyes to review it. As Uberon uses a custom release pipeline, we ask that you get at least one core developer to review it too.</li> <li>Merge to main branch once reviewed and CI checks have passed</li> <li>Deploy release on GitHub by running <code>make public_release GHVERSION=\"v2025-08-15\"</code> on the release branch (DO NOTE CHANGE TO MAIN BRANCH!), replacing the date with the date of release (NOTE: no <code>sh run.sh</code>) Editors note: ODK 1.3.2 will have a feature to run the release from inside the docker container. For now deploy_release has to be run outside.</li> <li>This should end with a GitHub release link that looks something like: <pre><code>https://github.com/obophenotype/uberon/releases/tag/untagged-8935f3432525b27a0d84\n</code></pre> Copy the link and paste it in your browser, this should show you a draft release. </li> <li>Click the edit button (the pencil button on the top right corner) and change the tag to the GHVERSION you entered above (eg v2022-06-20)</li> <li>Change the <code>TBD.</code> in the main text to a summary of the main changes in the release if needed.</li> <li>Scroll down all the way and click the <code>update release</code> button. </li> </ol>"},{"location":"uberon-release/#common-issues","title":"Common issues","text":"<p>If you face an error like: <pre><code>HTTP 400: Bad Content-Length: (https://uploads.github.com/repos/obophenotype/uberon/releases/69827000/assets?label=&amp;name=life-stages-minimal.tsv)\nmake: *** [deploy_release] Error 1\n</code></pre> run <pre><code>echo \"empty\" &gt; ../../subsets/life-stages-minimal.tsv\n</code></pre></p>"},{"location":"uberon_build_pipeline/","title":"The Uberon Build System","text":""},{"location":"uberon_build_pipeline/#overview","title":"Overview","text":"<p>Uberon used to have a completely custom, ad-hoc build pipeline that only Chris Mungall knew how to run. Since 2021, the pipeline was migrated to a more standard ODK-based setup, with all the Uberon-specific bits handled by the custom <code>src/ontology/uberon.Makefile</code>.</p> <p>The repository now uses the typical ODK layout, and the following aspects of the pipeline are managed by the ODK in a standard way:</p> <ul> <li>the imports;</li> <li>the production of the \u201cvariants\u201d of the main release artifacts   (<code>-base</code>, <code>-full</code>, <code>-simple</code>, etc.);</li> <li>most of the reports and QC checks.</li> </ul> <p>The non-standard parts of the pipeline concerns mainly:</p> <ul> <li>the production of the main <code>uberon.owl</code> product;</li> <li>the production of ontology subsets;</li> <li>the production of the cross-species bridge files and   collected/composite ontologies;</li> <li>the production of extra QC checks and reports (notably the checks for   violations of taxon constraints and all the checks involving the   bridge files).</li> </ul>"},{"location":"uberon_build_pipeline/#notes-about-the-custom-pipelines","title":"Notes about the custom pipelines","text":"<p>This section is not intended to provide a complete explanation of how the custom pipeline works. Not that such an explanation would not be useful, but it would be likely to become quickly out-of-sync with the actual pipeline code. Ultimately, the reference for how those pipelines work is the <code>uberon.Makefile</code> file. Consider this section merely as a guide to orient yourself within that Makefile.</p> <p>Unless otherwise noted:</p> <ul> <li>all filenames are relative to the <code>src/ontology</code> directory;</li> <li>all steps are performed with ROBOT.</li> </ul>"},{"location":"uberon_build_pipeline/#building-the-main-uberonowl-product","title":"Building the main <code>uberon.owl</code> product","text":"<p>Two-steps process:</p> <ul> <li><code>tmp/uberon-edit.owl</code>: made by merging the main source file   (<code>uberon-edit.obo</code>) along with the ODK import module and all the   various components; OWL macros are expanded in that step;</li> <li><code>uberon.owl</code>: reasoning step.</li> </ul> <p>The second step notably includes a materialisation phase that is particularly memory intensive and that must therefore be excluded when running the pipeline on memory-constrained machines (any machine with less than 32 GB of RAM is considered to be memory-constrained when Uberon is concerned). Run the pipeline with <code>GH_ACTION=true</code> to exclude that materialisation step (do not do that when trying to produce an official release!).</p>"},{"location":"uberon_build_pipeline/#building-the-multi-species-ontologies","title":"Building the multi-species ontologies","text":"<p>This is decomposed in several steps that are mostly isolated from each other, so that each step can be run independently.</p> <ol> <li>Building Uberon itself (<code>sh run.sh make uberon.owl</code>).</li> <li>Mirroring the taxon-specific ontologies (<code>sh run.sh make MIR=true    IMP=true all_local_imports</code>).</li> <li>Mirroring the externally provided mapping sets (<code>sh run.sh make    refresh-mappings</code>).</li> <li>Building the cross-species bridges (<code>sh run.sh make    refresh-bridges</code>).</li> <li>Building the desired collected or composite ontology (e.g. <code>sh run.sh    make composite-metazoan.owl</code>).</li> </ol> <p>Steps 2\u20134 can also be run in a single command with <code>sh run.sh make refresh-external-resources</code> (this will also refresh the standard ODK import module).</p>"},{"location":"odk-workflows/","title":"Default ODK Workflows","text":"<ul> <li>Daily Editors Workflow</li> <li>Release Workflow</li> <li>Manage your ODK Repository</li> <li>Setting up Docker for ODK</li> <li>Imports management</li> <li>Managing the documentation</li> <li>Managing your Automated Testing</li> </ul>"},{"location":"odk-workflows/ContinuousIntegration/","title":"Introduction to Continuous Integration Workflows with ODK","text":"<p>Historically, most repos have been using Travis CI for continuous integration testing and building, but due to runtime restrictions, we recently switched a lot of our repos to GitHub actions. You can set up your repo with CI by adding  this to your configuration file (src/ontology/uberon-odk.yaml):</p> <pre><code>ci:\n  - github_actions\n</code></pre> <p>When updateing your repo, you will notice a new file being added: <code>.github/workflows/qc.yml</code>.</p> <p>This file contains your CI logic, so if you need to change, or add anything, this is the place!</p> <p>Alternatively, if your repo is in GitLab instead of GitHub, you can set up your repo with GitLab CI by adding  this to your configuration file (src/ontology/uberon-odk.yaml):</p> <pre><code>ci:\n  - gitlab-ci\n</code></pre> <p>This will add a file called <code>.gitlab-ci.yml</code> in the root of your repo.</p>"},{"location":"odk-workflows/EditorsWorkflow/","title":"Editors Workflow","text":"<p>The editors workflow is one of the formal workflows to ensure that the ontology is developed correctly according to ontology engineering principles. There are a few different editors workflows:</p> <ol> <li>Local editing workflow: Editing the ontology in your local environment by hand, using tools such as Prot\u00e9g\u00e9, ROBOT templates or DOSDP patterns.</li> <li>Completely automated data pipeline (GitHub Actions)</li> <li>DROID workflow</li> </ol> <p>This document only covers the first editing workflow, but more will be added in the future</p>"},{"location":"odk-workflows/EditorsWorkflow/#local-editing-workflow","title":"Local editing workflow","text":"<p>Workflow requirements:</p> <ul> <li>git</li> <li>github</li> <li>docker</li> <li>editing tool of choice, e.g. Prot\u00e9g\u00e9, your favourite text editor, etc</li> </ul>"},{"location":"odk-workflows/EditorsWorkflow/#1-create-issue","title":"1. Create issue","text":"<p>Ensure that there is a ticket on your issue tracker that describes the change you are about to make. While this seems optional, this is a very important part of the social contract of building an ontology - no change to the ontology should be performed without a good ticket, describing the motivation and nature of the intended change.</p>"},{"location":"odk-workflows/EditorsWorkflow/#2-update-main-branch","title":"2. Update main branch","text":"<p>In your local environment (e.g. your laptop), make sure you are on the <code>main</code> (prev. <code>master</code>) branch and ensure that you have all the upstream changes, for example:</p> <pre><code>git checkout master\ngit pull\n</code></pre>"},{"location":"odk-workflows/EditorsWorkflow/#3-create-feature-branch","title":"3. Create feature branch","text":"<p>Create a new branch. Per convention, we try to use meaningful branch names such as: - issue23removeprocess (where issue 23 is the related issue on GitHub) - issue26addcontributor - release20210101 (for releases)</p> <p>On your command line, this looks like this:</p> <pre><code>git checkout -b issue23removeprocess\n</code></pre>"},{"location":"odk-workflows/EditorsWorkflow/#4-perform-edit","title":"4. Perform edit","text":"<p>Using your editor of choice, perform the intended edit. For example:</p> <p>Prot\u00e9g\u00e9</p> <ol> <li>Open <code>src/ontology/uberon-edit.owl</code> in Prot\u00e9g\u00e9</li> <li>Make the change</li> <li>Save the file</li> </ol> <p>TextEdit</p> <ol> <li>Open <code>src/ontology/uberon-edit.owl</code> in TextEdit (or Sublime, Atom, Vim, Nano)</li> <li>Make the change</li> <li>Save the file</li> </ol> <p>Consider the following when making the edit.</p> <ol> <li>According to our development philosophy, the only places that should be manually edited are:<ul> <li><code>src/ontology/uberon-edit.owl</code></li> <li>Any ROBOT templates you chose to use (the TSV files only)</li> <li>Any DOSDP data tables you chose to use (the TSV files, and potentially the associated patterns)</li> <li>components (anything in <code>src/ontology/components</code>), see here.</li> </ul> </li> <li>Imports should not be edited (any edits will be flushed out with the next update). However, refreshing imports is a potentially breaking change - and is discussed elsewhere.</li> <li>Changes should usually be small. Adding or changing 1 term is great. Adding or changing 10 related terms is ok. Adding or changing 100 or more terms at once should be considered very carefully.</li> </ol>"},{"location":"odk-workflows/EditorsWorkflow/#4-check-the-git-diff","title":"4. Check the Git diff","text":"<p>This step is very important. Rather than simply trusting your change had the intended effect, we should always use a git diff as a first pass for sanity checking.</p> <p>In our experience, having a visual git client like GitHub Desktop or sourcetree is really helpful for this part. In case you prefer the command line:</p> <pre><code>git status\ngit diff\n</code></pre>"},{"location":"odk-workflows/EditorsWorkflow/#5-quality-control","title":"5. Quality control","text":"<p>Now it's time to run your quality control checks. This can either happen locally (5a) or through your continuous integration system (7/5b).</p>"},{"location":"odk-workflows/EditorsWorkflow/#5a-local-testing","title":"5a. Local testing","text":"<p>If you chose to run your test locally:</p> <p><pre><code>sh run.sh make IMP=false test\n</code></pre> This will run the whole set of configured ODK tests on including your change. If you have a complex DOSDP pattern pipeline you may want to add <code>PAT=false</code> to skip the potentially lengthy process of rebuilding the patterns.</p> <pre><code>sh run.sh make IMP=false PAT=false test\n</code></pre>"},{"location":"odk-workflows/EditorsWorkflow/#6-pull-request","title":"6. Pull request","text":"<p>When you are happy with the changes, you commit your changes to your feature branch, push them upstream (to GitHub) and create a pull request. For example:</p> <pre><code>git add NAMEOFCHANGEDFILES\ngit commit -m \"Added biological process term #12\"\ngit push -u origin issue23removeprocess\n</code></pre> <p>Then you go to your project on GitHub, and create a new pull request from the branch, for example: https://github.com/INCATools/ontology-development-kit/pulls</p> <p>There is a lot of great advise on how to write pull requests, but at the very least you should: - mention the tickets affected: <code>see #23</code> to link to a related ticket, or <code>fixes #23</code> if, by merging this pull request, the ticket is fixed. Tickets in the latter case will be closed automatically by GitHub when the pull request is merged. - summarise the changes in a few sentences. Consider the reviewer: what would they want to know right away. - If the diff is large, provide instructions on how to review the pull request best (sometimes, there are many changed files, but only one important change).</p>"},{"location":"odk-workflows/EditorsWorkflow/#75b-continuous-integration-testing","title":"7/5b. Continuous Integration Testing","text":"<p>If you didn't run and local quality control checks (see 5a), you should have Continuous Integration (CI) set up, for example: - Travis - GitHub Actions</p> <p>More on how to set this up here. Once the pull request is created, the CI will automatically trigger. If all is fine, it will show up green, otherwise red.</p>"},{"location":"odk-workflows/EditorsWorkflow/#8-community-review","title":"8. Community review","text":"<p>Once all the automatic tests have passed, it is important to put a second set of eyes on the pull request. Ontologies are inherently social - as in that they represent some kind of community consensus on how a domain is organised conceptually. This seems high brow talk, but it is very important that as an ontology editor, you have your work validated by the community you are trying to serve (e.g. your colleagues, other contributors etc.). In our experience, it is hard to get more than one review on a pull request - two is great. You can set up GitHub branch protection to actually require a review before a pull request can be merged! We recommend this.</p> <p>This step seems daunting to some hopefully under-resourced ontologies, but we recommend to put this high up on your list of priorities - train a colleague, reach out!</p>"},{"location":"odk-workflows/EditorsWorkflow/#9-merge-and-cleanup","title":"9. Merge and cleanup","text":"<p>When the QC is green and the reviews are in (approvals), it is time to merge the pull request. After the pull request is merged, remember to delete the branch as well (this option will show up as a big button right after you have merged the pull request). If you have not done so, close all the associated tickets fixed by the pull request.</p>"},{"location":"odk-workflows/EditorsWorkflow/#10-changelog-optional","title":"10. Changelog (Optional)","text":"<p>It is sometimes difficult to keep track of changes made to an ontology. Some ontology teams opt to document changes in a changelog (simply a text file in your repository) so that when release day comes, you know everything you have changed. This is advisable at least for major changes (such as a new release system, a new pattern or template etc.).</p>"},{"location":"odk-workflows/ManageAutomatedTest/","title":"Manage automated checks","text":""},{"location":"odk-workflows/ManageAutomatedTest/#constraint-violation-checks","title":"Constraint violation checks","text":"<p>We can define custom checks using SPARQL. SPARQL queries define bad modelling patterns (missing labels, misspelt URIs, and many more) in the ontology. If these queries return any results, then the build will fail. Custom checks are designed to be run as part of GitHub Actions Continuous Integration testing, but they can also run locally.</p>"},{"location":"odk-workflows/ManageAutomatedTest/#steps-to-add-a-constraint-violation-check","title":"Steps to add a constraint violation check:","text":"<ol> <li>Add the SPARQL query in <code>src/sparql</code>. The name of the file should end with <code>-violation.sparql</code>. Please give a name that helps to understand which violation the query wants to check.</li> <li>Add the name of the new file to odk configuration file <code>src/ontology/uberon-odk.yaml</code>:<ol> <li>Include the name of the file (without the <code>-violation.sparql</code> part) to the list inside the key <code>custom_sparql_checks</code> that is inside <code>robot_report</code> key.</li> <li> <p>If the <code>robot_report</code> or <code>custom_sparql_checks</code> keys are not available, please add this code block to the end of the file.</p> <p><pre><code>  robot_report:\n    release_reports: False\n    fail_on: ERROR\n    use_labels: False\n    custom_profile: True\n    report_on:\n      - edit\n    custom_sparql_checks:\n      - name-of-the-file-check\n</code></pre> 3. Update the repository so your new SPARQL check will be included in the QC.</p> </li> </ol> </li> </ol> <pre><code>sh run.sh make update_repo\n</code></pre>"},{"location":"odk-workflows/ManageDocumentation/","title":"Updating the Documentation","text":"<p>The documentation for UBERON is managed in two places (relative to the repository root):</p> <ol> <li>The <code>docs</code> directory contains all the files that pertain to the content of the documentation (more below)</li> <li>the <code>mkdocs.yaml</code> file contains the documentation config, in particular its navigation bar and theme.</li> </ol> <p>The documentation is hosted using GitHub pages, on a special branch of the repository (called <code>gh-pages</code>). It is important that this branch is never deleted - it contains all the files GitHub pages needs to render and deploy the site. It is also important to note that the gh-pages branch should never be edited manually. All changes to the docs happen inside the <code>docs</code> directory on the <code>main</code> branch.</p>"},{"location":"odk-workflows/ManageDocumentation/#editing-the-docs","title":"Editing the docs","text":""},{"location":"odk-workflows/ManageDocumentation/#changing-content","title":"Changing content","text":"<p>All the documentation is contained in the <code>docs</code> directory, and is managed in Markdown. Markdown is a very simple and convenient way to produce text documents with formatting instructions, and is very easy to learn - it is also used, for example, in GitHub issues. This is a normal editing workflow:</p> <ol> <li>Open the <code>.md</code> file you want to change in an editor of choice (a simple text editor is often best). IMPORTANT: Do not edit any files in the <code>docs/odk-workflows/</code> directory. These files are managed by the ODK system and will be overwritten when the repository is upgraded! If you wish to change these files, make an issue on the ODK issue tracker.</li> <li>Perform the edit and save the file</li> <li>Commit the file to a branch, and create a pull request as usual. </li> <li>If your development team likes your changes, merge the docs into master branch.</li> <li>Deploy the documentation (see below)</li> </ol>"},{"location":"odk-workflows/ManageDocumentation/#deploy-the-documentation","title":"Deploy the documentation","text":"<p>The documentation is not automatically updated from the Markdown, and needs to be deployed deliberately. To do this, perform the following steps:</p> <ol> <li>In your terminal, navigate to the edit directory of your ontology, e.g.:    <pre><code>cd uberon/src/ontology\n</code></pre></li> <li>Now you are ready to build the docs as follows:    <pre><code>sh run.sh make update_docs\n</code></pre> Mkdocs now sets off to build the site from the markdown pages. You will be asked to<ul> <li>Enter your username</li> <li>Enter your password (see here for using GitHub access tokens instead)   IMPORTANT: Using password based authentication will be deprecated this year (2021). Make sure you read up on personal access tokens if that happens!</li> </ul> </li> </ol> <p>If everything was successful, you will see a message similar to this one:</p> <p><pre><code>INFO    -  Your documentation should shortly be available at: https://obophenotype.github.io/uberon/ \n</code></pre> 3. Just to double check, you can now navigate to your documentation pages (usually https://obophenotype.github.io/uberon/).     Just make sure you give GitHub 2-5 minutes to build the pages!</p>"},{"location":"odk-workflows/ReleaseWorkflow/","title":"The release workflow","text":"<p>The release workflow recommended by the ODK is based on GitHub releases and works as follows:</p> <ol> <li>Run a release with the ODK</li> <li>Review the release</li> <li>Merge to main branch</li> <li>Create a GitHub release</li> </ol> <p>These steps are outlined in detail in the following.</p>"},{"location":"odk-workflows/ReleaseWorkflow/#run-a-release-with-the-odk","title":"Run a release with the ODK","text":"<p>Preparation:</p> <ol> <li>Ensure that all your pull requests are merged into your main (master) branch</li> <li>Make sure that all changes to master are committed to GitHub (<code>git status</code> should say that there are no modified files)</li> <li>Locally make sure you have the latest changes from master (<code>git pull</code>)</li> <li>Checkout a new branch (e.g. <code>git checkout -b release-2021-01-01</code>)</li> <li>You may or may not want to refresh your imports as part of your release strategy (see here)</li> <li>Make sure you have the latest ODK installed by running <code>docker pull obolibrary/odkfull</code></li> </ol> <p>To actually run the release, you:</p> <ol> <li>Open a command line terminal window and navigate to the src/ontology directory (<code>cd uberon/src/ontology</code>)</li> <li>Run release pipeline:<code>sh run.sh make prepare_release -B</code>. Note that for some ontologies, this process can take up to 90 minutes - especially if there are large ontologies you depend on, like PRO or CHEBI.</li> <li>If everything went well, you should see the following output on your machine: <code>Release files are now in ../.. - now you should commit, push and make a release on your git hosting site such as GitHub or GitLab</code>.</li> </ol> <p>This will create all the specified release targets (OBO, OWL, JSON, and the variants, ont-full and ont-base) and copy them into your release directory (the top level of your repo).</p>"},{"location":"odk-workflows/ReleaseWorkflow/#review-the-release","title":"Review the release","text":"<ol> <li>(Optional) Rough check. This step is frequently skipped, but for the more paranoid among us (like the author of this doc), this is a 3 minute additional effort for some peace of mind. Open the main release (uberon.owl) in you favourite development environment (i.e. Prot\u00e9g\u00e9) and eyeball the hierarchy. We recommend two simple checks: <ol> <li>Does the very top level of the hierarchy look ok? This means that all new terms have been imported/updated correctly.</li> <li>Does at least one change that you know should be in this release appear? For example, a new class. This means that the release was actually based on the recent edit file. </li> </ol> </li> <li>Commit your changes to the branch and make a pull request</li> <li>In your GitHub pull request, review the following three files in detail (based on our experience):<ol> <li><code>uberon.obo</code> - this reflects a useful subset of the whole ontology (everything that can be covered by OBO format). OBO format has that speaking for it: it is very easy to review!</li> <li><code>uberon-base.owl</code> - this reflects the asserted axioms in your ontology that you have actually edited.</li> <li>Ideally also take a look at <code>uberon-full.owl</code>, which may reveal interesting new inferences you did not know about. Note that the diff of this file is sometimes quite large.</li> </ol> </li> <li>Like with every pull request, we recommend to always employ a second set of eyes when reviewing a PR!</li> </ol>"},{"location":"odk-workflows/ReleaseWorkflow/#merge-the-main-branch","title":"Merge the main branch","text":"<p>Once your CI checks have passed, and your reviews are completed, you can now merge the branch into your main branch (don't forget to delete the branch afterwards - a big button will appear after the merge is finished).</p>"},{"location":"odk-workflows/ReleaseWorkflow/#create-a-github-release","title":"Create a GitHub release","text":"<ol> <li>Go to your releases page on GitHub by navigating to your repository, and then clicking on releases (usually on the right, for example: https://github.com/obophenotype/uberon/releases). Then click \"Draft new release\"</li> <li>As the tag version you need to choose the date on which your ontologies were build. You can find this, for example, by looking at the <code>uberon.obo</code> file and check the <code>data-version:</code> property. The date needs to be prefixed with a <code>v</code>, so, for example <code>v2020-02-06</code>.</li> <li>You can write whatever you want in the release title, but we typically write the date again. The description underneath should contain a concise list of changes or term additions.</li> <li>Click \"Publish release\". Done.</li> </ol>"},{"location":"odk-workflows/ReleaseWorkflow/#debugging-typical-ontology-release-problems","title":"Debugging typical ontology release problems","text":""},{"location":"odk-workflows/ReleaseWorkflow/#problems-with-memory","title":"Problems with memory","text":"<p>When you are dealing with large ontologies, you need a lot of memory. When you see error messages relating to large ontologies such as CHEBI, PRO, NCBITAXON, or Uberon, you should think of memory first, see here.</p>"},{"location":"odk-workflows/ReleaseWorkflow/#problems-when-using-obo-format-based-tools","title":"Problems when using OBO format based tools","text":"<p>Sometimes you will get cryptic error messages when using legacy tools using OBO format, such as the ontology release tool (OORT), which is also available as part of the ODK docker container. In these cases, you need to track down what axiom or annotation actually caused the breakdown. In our experience (in about 60% of the cases) the problem lies with duplicate annotations (<code>def</code>, <code>comment</code>) which are illegal in OBO. Here is an example recipe of how to deal with such a problem:</p> <ol> <li>If you get a message like <code>make: *** [cl.Makefile:84: oort] Error 255</code> you might have a OORT error. </li> <li>To debug this, in your terminal enter <code>sh run.sh make IMP=false PAT=false oort -B</code> (assuming you are already in the ontology folder in your directory) </li> <li>This should show you where the error is in the log (eg multiple different definitions)  WARNING: THE FIX BELOW IS NOT IDEAL, YOU SHOULD ALWAYS TRY TO FIX UPSTREAM IF POSSIBLE</li> <li>Open <code>uberon-edit.owl</code> in Prot\u00e9g\u00e9 and find the offending term and delete all offending issue (e.g. delete ALL definition, if the problem was \"multiple def tags not allowed\") and save.  *While this is not idea, as it will remove all definitions from that term, it will be added back again when the term is fixed in the ontology it was imported from and added back in.</li> <li>Rerun <code>sh run.sh make IMP=false PAT=false oort -B</code> and if it all passes, commit your changes to a branch and make a pull request as usual.</li> </ol>"},{"location":"odk-workflows/RepoManagement/","title":"Managing your ODK repository","text":""},{"location":"odk-workflows/RepoManagement/#updating-your-odk-repository","title":"Updating your ODK repository","text":"<p>Your ODK repositories configuration is managed in <code>src/ontology/uberon-odk.yaml</code>. The ODK Project Configuration Schema defines all possible parameters that can be used in this config YAML. Once you have made your changes, you can run the following to apply your changes to the repository:</p> <pre><code>sh run.sh make update_repo\n</code></pre> <p>There are a large number of options that can be set to configure your ODK, but we will only discuss a few of them here.</p> <p>NOTE for Windows users:</p> <p>You may get a cryptic failure such as <code>Set Illegal Option -</code> if the update script located in <code>src/scripts/update_repo.sh</code>  was saved using Windows Line endings. These need to change to unix line endings. In Notepad++, for example, you can  click on Edit-&gt;EOL Conversion-&gt;Unix LF to change this.</p>"},{"location":"odk-workflows/RepoManagement/#managing-imports","title":"Managing imports","text":"<p>You can use the update repository workflow described on this page to perform the following operations to your imports:</p> <ol> <li>Add a new import</li> <li>Modify an existing import</li> <li>Remove an import you no longer want</li> <li>Customise an import</li> </ol> <p>We will discuss all these workflows in the following.</p>"},{"location":"odk-workflows/RepoManagement/#add-new-import","title":"Add new import","text":"<p>To add a new import, you first edit your odk config as described above, adding an <code>id</code> to the <code>product</code> list in the <code>import_group</code> section (for the sake of this example, we assume you already import RO, and your goal is to also import GO):</p> <pre><code>import_group:\n  products:\n    - id: ro\n    - id: go\n</code></pre> <p>Note: our ODK file should only have one <code>import_group</code> which can contain multiple imports (in the <code>products</code> section). Next, you run the update repo workflow to apply these changes. Note that by default, this module is going to be a SLME Bottom module, see here. To change that or customise your module, see section \"Customise an import\". To finalise the addition of your import, perform the following steps:</p> <ol> <li>Add an import statement to your <code>src/ontology/uberon-edit.owl</code> file. We suggest to do this using a text editor, by simply copying an existing import declaration and renaming it to the new ontology import, for example as follows:     <pre><code>...\nOntology(&lt;http://purl.obolibrary.org/obo/uberon.owl&gt;\nImport(&lt;http://purl.obolibrary.org/obo/uberon/imports/ro_import.owl&gt;)\nImport(&lt;http://purl.obolibrary.org/obo/uberon/imports/go_import.owl&gt;)\n...\n</code></pre></li> <li>Add your imports redirect to your catalog file <code>src/ontology/catalog-v001.xml</code>, for example:     <pre><code>&lt;uri name=\"http://purl.obolibrary.org/obo/uberon/imports/go_import.owl\" uri=\"imports/go_import.owl\"/&gt;\n</code></pre></li> <li>Test whether everything is in order:<ol> <li>Refresh your import</li> <li>Open in your Ontology Editor of choice (Protege) and ensure that the expected terms are imported.</li> </ol> </li> </ol> <p>Note: The catalog file <code>src/ontology/catalog-v001.xml</code> has one purpose: redirecting  imports from URLs to local files. For example, if you have</p> <pre><code>Import(&lt;http://purl.obolibrary.org/obo/uberon/imports/go_import.owl&gt;)\n</code></pre> <p>in your editors file (the ontology) and</p> <pre><code>&lt;uri name=\"http://purl.obolibrary.org/obo/uberon/imports/go_import.owl\" uri=\"imports/go_import.owl\"/&gt;\n</code></pre> <p>in your catalog, tools like <code>robot</code> or Prot\u00e9g\u00e9 will recognize the statement in the catalog file to redirect the URL <code>http://purl.obolibrary.org/obo/uberon/imports/go_import.owl</code> to the local file <code>imports/go_import.owl</code> (which is in your <code>src/ontology</code> directory).</p>"},{"location":"odk-workflows/RepoManagement/#modify-an-existing-import","title":"Modify an existing import","text":"<p>If you simply wish to refresh your import in light of new terms, see here. If you wish to change the type of your module see section \"Customise an import\".</p>"},{"location":"odk-workflows/RepoManagement/#remove-an-existing-import","title":"Remove an existing import","text":"<p>To remove an existing import, perform the following steps:</p> <ol> <li>remove the import declaration from your <code>src/ontology/uberon-edit.owl</code>.</li> <li>remove the id from your <code>src/ontology/uberon-odk.yaml</code>, eg. <code>- id: go</code> from the list of <code>products</code> in the <code>import_group</code>.</li> <li>run update repo workflow</li> <li>delete the associated files manually:<ul> <li><code>src/imports/go_import.owl</code></li> <li><code>src/imports/go_terms.txt</code></li> </ul> </li> <li>Remove the respective entry from the <code>src/ontology/catalog-v001.xml</code> file.</li> </ol>"},{"location":"odk-workflows/RepoManagement/#customise-an-import","title":"Customise an import","text":"<p>By default, an import module extracted from a source ontology will be a SLME module, see here. There are various options to change the default.</p> <p>The following change to your repo config (<code>src/ontology/uberon-odk.yaml</code>) will switch the go import from an SLME module to a simple ROBOT filter module:</p> <pre><code>import_group:\n  products:\n    - id: ro\n    - id: go\n      module_type: filter\n</code></pre> <p>A ROBOT filter module is, essentially, importing all external terms declared by your ontology (see here on how to declare external terms to be imported). Note that the <code>filter</code> module does  not consider terms/annotations from namespaces other than the base-namespace of the ontology itself. For example, in the example of GO above, only annotations / axioms related to the GO base IRI (http://purl.obolibrary.org/obo/GO_) would be considered. This  behaviour can be changed by adding additional base IRIs as follows:</p> <pre><code>import_group:\n  products:\n    - id: go\n      module_type: filter\n      base_iris:\n        - http://purl.obolibrary.org/obo/GO_\n        - http://purl.obolibrary.org/obo/CL_\n        - http://purl.obolibrary.org/obo/BFO\n</code></pre> <p>If you wish to customise your import entirely, you can specify your own ROBOT command to do so. To do that, add the following to your repo config (<code>src/ontology/uberon-odk.yaml</code>):</p> <pre><code>import_group:\n  products:\n    - id: ro\n    - id: go\n      module_type: custom\n</code></pre> <p>Now add a new goal in your custom Makefile (<code>src/ontology/uberon.Makefile</code>, not <code>src/ontology/Makefile</code>).</p> <pre><code>imports/go_import.owl: mirror/ro.owl imports/ro_terms_combined.txt\n    if [ $(IMP) = true ]; then $(ROBOT) query  -i $&lt; --update ../sparql/preprocess-module.ru \\\n        extract -T imports/ro_terms_combined.txt --force true --individuals exclude --method BOT \\\n        query --update ../sparql/inject-subset-declaration.ru --update ../sparql/postprocess-module.ru \\\n        annotate --ontology-iri $(ONTBASE)/$@ $(ANNOTATE_ONTOLOGY_VERSION) --output $@.tmp.owl &amp;&amp; mv $@.tmp.owl $@; fi\n</code></pre> <p>Now feel free to change this goal to do whatever you wish it to do! It probably makes some sense (albeit not being a strict necessity), to leave most of the goal instead and replace only:</p> <pre><code>extract -T imports/ro_terms_combined.txt --force true --individuals exclude --method BOT \\\n</code></pre> <p>to another ROBOT pipeline.</p>"},{"location":"odk-workflows/RepoManagement/#add-a-component","title":"Add a component","text":"<p>A component is an import which belongs to your ontology, e.g. is managed by  you and your team. </p> <ol> <li>Open <code>src/ontology/uberon-odk.yaml</code></li> <li>If you dont have it yet, add a new top level section <code>components</code></li> <li>Under the <code>components</code> section, add a new section called <code>products</code>.  This is where all your components are specified</li> <li>Under the <code>products</code> section, add a new component, e.g. <code>- filename: mycomp.owl</code></li> </ol> <p>Example</p> <pre><code>components:\n  products:\n    - filename: mycomp.owl\n</code></pre> <p>When running <code>sh run.sh make update_repo</code>, a new file <code>src/ontology/components/mycomp.owl</code> will  be created which you can edit as you see fit. Typical ways to edit:</p> <ol> <li>Using a ROBOT template to generate the component (see below)</li> <li>Manually curating the component separately with Prot\u00e9g\u00e9 or any other editor</li> <li>Providing a <code>components/mycomp.owl:</code> make target in <code>src/ontology/uberon.Makefile</code> and provide a custom command to generate the component<ul> <li><code>WARNING</code>: Note that the custom rule to generate the component MUST NOT depend on any other ODK-generated file such as seed files and the like (see issue).</li> </ul> </li> <li>Providing an additional attribute for the component in <code>src/ontology/uberon-odk.yaml</code>, <code>source</code>, to specify that this component should simply be downloaded from somewhere on the web.</li> </ol>"},{"location":"odk-workflows/RepoManagement/#adding-a-new-component-based-on-a-robot-template","title":"Adding a new component based on a ROBOT template","text":"<p>Since ODK 1.3.2, it is possible to simply link a ROBOT template to a component without having to specify any of the import logic. In order to add a new component that is connected to one or more template files, follow these steps:</p> <ol> <li>Open <code>src/ontology/uberon-odk.yaml</code>.</li> <li>Make sure that <code>use_templates: TRUE</code> is set in the global project options. You should also make sure that <code>use_context: TRUE</code> is set in case you are using prefixes in your templates that are not known to <code>robot</code>, such as <code>OMOP:</code>, <code>CPONT:</code> and more. All non-standard prefixes you are using should be added to <code>config/context.json</code>.</li> <li>Add another component to the <code>products</code> section.</li> <li>To activate this component to be template-driven, simply say: <code>use_template: TRUE</code>. This will create an empty template for you in the templates directory, which will automatically be processed when recreating the component (e.g. <code>run.bat make recreate-mycomp</code>).</li> <li>If you want to use more than one component, use the <code>templates</code> field to add as many template names as you wish. ODK will look for them in the <code>src/templates</code> directory.</li> <li>Advanced: If you want to provide additional processing options, you can use the <code>template_options</code> field. This should be a string with option from robot template. One typical example for additional options you may want to provide is <code>--add-prefixes config/context.json</code> to ensure the prefix map of your context is provided to <code>robot</code>, see above.</li> </ol> <p>Example:</p> <pre><code>components:\n  products:\n    - filename: mycomp.owl\n      use_template: TRUE\n      template_options: --add-prefixes config/context.json\n      templates:\n        - template1.tsv\n        - template2.tsv\n</code></pre> <p>Note: if your mirror is particularly large and complex, read this ODK recommendation.</p>"},{"location":"odk-workflows/RepositoryFileStructure/","title":"Repository structure","text":"<p>The main kinds of files in the repository:</p> <ol> <li>Release files</li> <li>Imports</li> <li>Components</li> </ol>"},{"location":"odk-workflows/RepositoryFileStructure/#release-files","title":"Release files","text":"<p>Release file are the file that are considered part of the official ontology release and to be used by the community. A detailed description of the release artefacts can be found here.</p>"},{"location":"odk-workflows/RepositoryFileStructure/#imports","title":"Imports","text":"<p>Imports are subsets of external ontologies that contain terms and axioms you would like to re-use in your ontology. These are considered \"external\", like dependencies in software development, and are not included in your \"base\" product, which is the release artefact which contains only those axioms that you personally maintain.</p> <p>These are the current imports in UBERON</p> Import URL Type pr https://raw.githubusercontent.com/obophenotype/pro_obo_slim/master/pr_slim.owl slme cl http://purl.obolibrary.org/obo/cl.owl slme go http://purl.obolibrary.org/obo/go/go-base.owl slme envo http://purl.obolibrary.org/obo/envo.owl slme ro http://purl.obolibrary.org/obo/ro.owl slme bspo http://purl.obolibrary.org/obo/bspo.owl slme chebi https://raw.githubusercontent.com/obophenotype/chebi_obo_slim/main/chebi_slim.owl slme pato http://purl.obolibrary.org/obo/pato.owl slme bfo http://purl.obolibrary.org/obo/bfo.owl slme ncbitaxon http://purl.obolibrary.org/obo/ncbitaxon/subsets/taxslim.owl slme ncbitaxondisjoints http://purl.obolibrary.org/obo/ncbitaxon/subsets/taxslim-disjoint-over-in-taxon.owl slme nbo http://purl.obolibrary.org/obo/nbo.owl slme orcidio https://w3id.org/orcidio/orcidio.owl custom omo http://purl.obolibrary.org/obo/omo.owl mirror ## Components Components, in contrast to imports, are considered full members of the ontology. This means that any axiom in a component is also included in the ontology base - which means it is considered native to the ontology. While this sounds complicated, consider this: conceptually, no component should be part of more than one ontology. If that seems to be the case, we are most likely talking about an import. Components are often not needed for ontologies, but there are some use cases: <ol> <li>There is an automated process that generates and re-generates a part of the ontology</li> <li>A part of the ontology is managed in ROBOT templates</li> <li>The expressivity of the component is higher than the format of the edit file. For example, people still choose to manage their ontology in OBO format (they should not) missing out on a lot of owl features. They may choose to manage logic that is beyond OBO in a specific OWL component.</li> </ol> <p>These are the components in UBERON</p> Filename URL disjoint_union_over.owl None mappings.owl None in-subset.owl None hra_subset.owl https://raw.githubusercontent.com/hubmapconsortium/ccf-validation-tools/master/owl/UB_ASCTB_subset.owl vasculature_class.owl None hra_depiction_3d_images.owl https://raw.githubusercontent.com/hubmapconsortium/ccf-validation-tools/master/owl/hra_uberon_3d_images.owl"},{"location":"odk-workflows/SettingUpDockerForODK/","title":"Setting up your Docker environment for ODK use","text":"<p>One of the most frequent problems with running the ODK for the first time is failure because of lack of memory. This can look like a Java OutOfMemory exception,  but more often than not it will appear as something like an <code>Error 137</code>. There are two places you need to consider to set your memory:</p> <ol> <li>Your src/ontology/run.sh (or run.bat) file. You can set the memory in there by adding  <code>robot_java_args: '-Xmx8G'</code> to your src/ontology/uberon-odk.yaml file, see for example here.</li> <li>Set your docker memory. By default, it should be about 10-20% more than your <code>robot_java_args</code> variable. You can manage your memory settings by right-clicking on the docker whale in your system bar--&gt;Preferences--&gt;Resources--&gt;Advanced, see picture below.</li> </ol> <p></p>"},{"location":"odk-workflows/UpdateImports/","title":"Update Imports Workflow","text":"<p>This page discusses how to update the contents of your imports, like adding or removing terms. If you are looking to customise imports, like changing the module type, see here.</p>"},{"location":"odk-workflows/UpdateImports/#importing-a-new-term","title":"Importing a new term","text":"<p>Note: some ontologies now use a merged-import system to manage dynamic imports, for these please follow instructions in the section title \"Using the Base Module approach\".</p> <p>Importing a new term is split into two sub-phases:</p> <ol> <li>Declaring the terms to be imported</li> <li>Refreshing imports dynamically</li> </ol>"},{"location":"odk-workflows/UpdateImports/#declaring-terms-to-be-imported","title":"Declaring terms to be imported","text":"<p>There are three ways to declare terms that are to be imported from an external ontology. Choose the appropriate one for your particular scenario (all three can be used in parallel if need be):</p> <ol> <li>Prot\u00e9g\u00e9-based declaration</li> <li>Using term files</li> <li>Using the custom import template</li> </ol>"},{"location":"odk-workflows/UpdateImports/#protege-based-declaration","title":"Prot\u00e9g\u00e9-based declaration","text":"<p>This workflow is to be avoided, but may be appropriate if the editor does not have access to the ODK docker container.  This approach also applies to ontologies that use base module import approach.</p> <ol> <li>Open your ontology (edit file) in Prot\u00e9g\u00e9 (5.5+).</li> <li>Select 'owl:Thing'</li> <li>Add a new class as usual.</li> <li>Paste the full iri in the 'Name:' field, for example, http://purl.obolibrary.org/obo/CHEBI_50906.</li> <li>Click 'OK'</li> </ol> <p></p> <p>Now you can use this term for example to construct logical definitions. The next time the imports are refreshed (see how to refresh here), the metadata (labels, definitions, etc.) for this term are imported from the respective external source ontology and becomes visible in your ontology.</p>"},{"location":"odk-workflows/UpdateImports/#using-term-files","title":"Using term files","text":"<p>Every import has, by default a term file associated with it, which can be found in the imports directory. For example, if you have a GO import in <code>src/ontology/go_import.owl</code>, you will also have an associated term file <code>src/ontology/go_terms.txt</code>. You can add terms in there simply as a list:</p> <pre><code>GO:0008150\nGO:0008151\n</code></pre> <p>Now you can run the refresh imports workflow) and the two terms will be imported.</p>"},{"location":"odk-workflows/UpdateImports/#using-the-custom-import-template","title":"Using the custom import template","text":"<p>This workflow is appropriate if:</p> <ol> <li>You prefer to manage all your imported terms in a single file (rather than multiple files like in the \"Using term files\" workflow above).</li> <li>You wish to augment your imported ontologies with additional information. This requires a cautionary discussion.</li> </ol> <p>To enable this workflow, you add the following to your ODK config file (<code>src/ontology/uberon-odk.yaml</code>), and update the repository:</p> <pre><code>use_custom_import_module: TRUE\n</code></pre> <p>Now you can manage your imported terms directly in the custom external terms template, which is located at <code>src/templates/external_import.owl</code>. Note that this file is a ROBOT template, and can, in principle, be extended to include any axioms you like. Before extending the template, however, read the following carefully.</p> <p>The main purpose of the custom import template is to enable the management off all terms to be imported in a centralised place. To enable that, you do not have to do anything other than maintaining the template. So if you, say currently import <code>APOLLO_SV:00000480</code>, and you wish to import <code>APOLLO_SV:00000532</code>, you simply add a row like this:</p> <pre><code>ID  Entity Type\nID  TYPE\nAPOLLO_SV:00000480  owl:Class\nAPOLLO_SV:00000532  owl:Class\n</code></pre> <p>When the imports are refreshed see imports refresh workflow, the term(s) will simply be imported from the configured ontologies.</p> <p>Now, if you wish to extend the Makefile (which is beyond these instructions) and add, say, synonyms to the imported terms, you can do that, but you need to (a) preserve the <code>ID</code> and <code>ENTITY</code> columns and (b) ensure that the ROBOT template is valid otherwise, see here.</p> <p>WARNING. Note that doing this is a widespread antipattern (see related issue). You should not change the axioms of terms that do not belong into your ontology unless necessary - such changes should always be pushed into the ontology where they belong. However, since people are doing it, whether the OBO Foundry likes it or not, at least using the custom imports module as described here localises the changes to a single simple template and ensures that none of the annotations added this way are merged into the base file.  </p>"},{"location":"odk-workflows/UpdateImports/#refresh-imports","title":"Refresh imports","text":"<p>If you want to refresh the import yourself (this may be necessary to pass the travis tests), and you have the ODK installed, you can do the following (using go as an example):</p> <p>First, you navigate in your terminal to the ontology directory (underneath src in your hpo root directory).  <pre><code>cd src/ontology\n</code></pre></p> <p>Then, you regenerate the import that will now include any new terms you have added. Note: You must have docker installed.</p> <pre><code>sh run.sh make PAT=false imports/go_import.owl -B\n</code></pre> <p>Since ODK 1.2.27, it is also possible to simply run the following, which is the same as the above:</p> <pre><code>sh run.sh make refresh-go\n</code></pre> <p>Note that in case you changed the defaults, you need to add <code>IMP=true</code> and/or <code>MIR=true</code> to the command below:</p> <pre><code>sh run.sh make IMP=true MIR=true PAT=false imports/go_import.owl -B\n</code></pre> <p>If you wish to skip refreshing the mirror, i.e. skip downloading the latest version of the source ontology for your import (e.g. <code>go.owl</code> for your go import) you can set <code>MIR=false</code> instead, which will do the exact same thing as the above, but is easier to remember:</p> <pre><code>sh run.sh make IMP=true MIR=false PAT=false imports/go_import.owl -B\n</code></pre>"},{"location":"odk-workflows/UpdateImports/#using-the-base-module-approach","title":"Using the Base Module approach","text":"<p>Since ODK 1.2.31, we support an entirely new approach to generate modules: Using base files. The idea is to only import axioms from ontologies that actually belong to it.  A base file is a subset of the ontology that only contains those axioms that nominally  belong there. In other words, the base file does not contain any axioms that belong to another ontology. An example would be this:</p> <p>Imagine this being the full Uberon ontology:</p> <pre><code>Axiom 1: BFO:123 SubClassOf BFO:124\nAxiom 1: UBERON:123 SubClassOf BFO:123\nAxiom 1: UBERON:124 SubClassOf UBERON 123\n</code></pre> <p>The base file is the set of all axioms that are about UBERON terms:</p> <pre><code>Axiom 1: UBERON:123 SubClassOf BFO:123\nAxiom 1: UBERON:124 SubClassOf UBERON 123\n</code></pre> <p>I.e.</p> <pre><code>Axiom 1: BFO:123 SubClassOf BFO:124\n</code></pre> <p>Gets removed.</p> <p>The base file pipeline is a bit more complex than the normal pipelines, because of the logical interactions between the imported ontologies. This is solved by _first  merging all mirrors into one huge file and then extracting one mega module from it.</p> <p>Example: Let's say we are importing terms from Uberon, GO and RO in our ontologies. When we use the base pipelines, we</p> <p>1) First obtain the base (usually by simply downloading it, but there is also an option now to create it with ROBOT) 2) We merge all base files into one big pile 3) Then we extract a single module <code>imports/merged_import.owl</code></p> <p>The first implementation of this pipeline is PATO, see https://github.com/pato-ontology/pato/blob/master/src/ontology/pato-odk.yaml.</p> <p>To check if your ontology uses this method, check src/ontology/uberon-odk.yaml to see if <code>use_base_merging: TRUE</code> is declared under <code>import_group</code></p> <p>If your ontology uses Base Module approach, please use the following steps: </p> <p>First, add the term to be imported to the term file associated with it (see above \"Using term files\" section if this is not clear to you)</p> <p>Next, you navigate in your terminal to the ontology directory (underneath src in your hpo root directory).  <pre><code>cd src/ontology\n</code></pre></p> <p>Then refresh imports by running</p> <p><pre><code>sh run.sh make imports/merged_import.owl\n</code></pre> Note: if your mirrors are updated, you can run <code>sh run.sh make no-mirror-refresh-merged</code></p> <p>This requires quite a bit of memory on your local machine, so if you encounter an error, it might be a lack of memory on your computer. A solution would be to create a ticket in an issue tracker requesting for the term to be imported, and one of the local devs should pick this up and run the import for you.</p> <p>Lastly, restart Prot\u00e9g\u00e9, and the term should be imported in ready to be used.</p>"},{"location":"odk-workflows/components/","title":"Adding components to an ODK repo","text":"<p>For details on what components are, please see component section of repository file structure document.</p> <p>To add custom components to an ODK repo, please follow the following steps:</p> <p>1) Locate your odk yaml file and open it with your favourite text editor (src/ontology/uberon-odk.yaml) 2) Search if there is already a component section to the yaml file, if not add it accordingly, adding the name of your component:</p> <pre><code>components:\n  products:\n    - filename: your-component-name.owl\n</code></pre> <p>3) Refresh your repo by running <code>sh run update_repo</code>. This will automatically (1) create a new file in <code>src/ontology/components/</code>, (2) update the <code>-edit</code> file so that it imports <code>http://purl.obolibrary.org/obo/uberon/components/your-component-name.owl</code> (the IRI of your new component), and (3) update the XML catalog file (<code>src/ontology/catalog-v001.xml</code>) to redirect that IRI to the file in the <code>src/ontology/components</code> directory, so that the new component can be found by tools such as Prot\u00e9g\u00e9 or ROBOT, when they load the <code>-edit</code> file.</p> <p>If your component is to be generated by some automated process, add a goal in your custom Makefile (<code>src/ontology/uberon.Makefile</code>) and make it perform any task needed to generate the component:</p> <pre><code>$(COMPONENTSDIR)/your-component-name.owl: $(SRC)\n    &lt;Insert here the code to produce the component&gt;\n</code></pre> <p>If the component is to be generated from a ROBOT template, the ODK can generate the appropriate code for you. For that, when adding the component fo the ODK configuration file (step 2 above), explicitly indicate that the component should be derived from template(s) and list the source templates:</p> <pre><code>components:\n  products:\n    - filename: your-component-name.owl\n      use_template: true\n      templates:\n        - template1.tsv\n        - template2.tsv\n</code></pre> <p>In this example, the component will be derived from the templates found in <code>src/templates/template1.tsv</code> and <code>src/templates/template2.tsv</code>. Initial empty templates will automatically be generated when the repository is refreshed (step 3).</p> <p>Likewise, the ODK can generate the required code for the case where the component is to be derived from SSSOM mappings:</p> <pre><code>components:\n  products:\n    - filename: your-component-name.owl\n      use_mappings: true\n      mappings:\n        - my-mappings.sssom.tsv\n</code></pre> <p>and for the case where the component is to be fetched from a remote resource:</p> <pre><code>components:\n  products:\n    - filename: your-component-name.owl\n      source: https://example.org/component-source.owl\n</code></pre>"}]}